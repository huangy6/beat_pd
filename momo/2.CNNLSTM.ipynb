{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will create TFRecords dataset from the TFRecords file\n",
    "Generated from 1.datasetup. This record includes all the associated info with the downsampled 25hz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_mapper\n",
    "from importlib import reload\n",
    "reload(tf_mapper)\n",
    "from tf_mapper import get_batched_dataset\n",
    "# tf.enable_eager_execution()\n",
    "# Helperfunctions to make your feature definition more readable\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = { \\\n",
    "                'data':  tf.io.FixedLenFeature([1500*3], tf.float32,),\\\n",
    "                'on_off':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'dyskinesia':  tf.io.FixedLenFeature([1], tf.int64,),\n",
    "                'measurement_id':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'tremor':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                'age':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                \"subjects\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"gender\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartI_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartII_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.1\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.2\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.3\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.4\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.5\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.6\": tf.io.FixedLenFeature([1], tf.int64)\n",
    "               }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    return example\n",
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_is_in_set(a, b):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(b, a), tf.int64)) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = tf.data.Dataset.list_files(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\")\n",
    "option_no_order = tf.data.Options()\n",
    "option_no_order.experimental_deterministic = False\n",
    "dataset = dataset.with_options(option_no_order)\n",
    "dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=1, num_parallel_calls=1)\n",
    "\n",
    "dataset = dataset.map(read_tfrecord, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = dataset.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mini' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-57165eeb7c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mon_off\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mm_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"measurement_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mon_off\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"on_off\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mini' is not defined"
     ]
    }
   ],
   "source": [
    "m_id = []\n",
    "on_off = []\n",
    "for i in mini.make_one_shot_iterator():\n",
    "    m_id.append(i[\"measurement_id\"][0].numpy())\n",
    "    on_off.append(i[\"on_off\"][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([m_id, on_off]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0   \n",
       "0  4\n",
       "1  2\n",
       "2  0\n",
       "5  0\n",
       "6  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(0).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1970,\n",
       " 1403,\n",
       " 577,\n",
       " 1184,\n",
       " 1303,\n",
       " 145,\n",
       " 56,\n",
       " 1952,\n",
       " 881,\n",
       " 255,\n",
       " 838,\n",
       " 1229,\n",
       " 857,\n",
       " 1841,\n",
       " 2120,\n",
       " 576,\n",
       " 1908,\n",
       " 711,\n",
       " 1259,\n",
       " 527,\n",
       " 1304,\n",
       " 48,\n",
       " 1400,\n",
       " 603,\n",
       " 33,\n",
       " 1881,\n",
       " 1973,\n",
       " 2179,\n",
       " 113,\n",
       " 1055,\n",
       " 447,\n",
       " 575,\n",
       " 927,\n",
       " 1499,\n",
       " 1205,\n",
       " 2149,\n",
       " 1520,\n",
       " 21,\n",
       " 2159,\n",
       " 1822,\n",
       " 1988,\n",
       " 667,\n",
       " 593,\n",
       " 195,\n",
       " 859,\n",
       " 461,\n",
       " 1161,\n",
       " 395,\n",
       " 450,\n",
       " 1681,\n",
       " 556,\n",
       " 250,\n",
       " 924,\n",
       " 1762,\n",
       " 1274,\n",
       " 1725,\n",
       " 235,\n",
       " 495,\n",
       " 589,\n",
       " 1277,\n",
       " 1345,\n",
       " 2088,\n",
       " 2166,\n",
       " 658,\n",
       " 811,\n",
       " 624,\n",
       " 961,\n",
       " 2114,\n",
       " 311,\n",
       " 1296,\n",
       " 2088,\n",
       " 1469,\n",
       " 1175,\n",
       " 543,\n",
       " 1661,\n",
       " 1195,\n",
       " 782,\n",
       " 400,\n",
       " 1455,\n",
       " 122,\n",
       " 880,\n",
       " 660,\n",
       " 2060,\n",
       " 690,\n",
       " 17,\n",
       " 262,\n",
       " 1651,\n",
       " 1543,\n",
       " 1118,\n",
       " 1177,\n",
       " 1891,\n",
       " 1179,\n",
       " 1613,\n",
       " 997,\n",
       " 1753,\n",
       " 593,\n",
       " 971,\n",
       " 2038,\n",
       " 1015,\n",
       " 785,\n",
       " 1317,\n",
       " 107,\n",
       " 622,\n",
       " 1108,\n",
       " 605,\n",
       " 963,\n",
       " 799,\n",
       " 1669,\n",
       " 1214,\n",
       " 1188,\n",
       " 1724,\n",
       " 692,\n",
       " 1759,\n",
       " 1791,\n",
       " 1007,\n",
       " 676,\n",
       " 179,\n",
       " 1455,\n",
       " 2112,\n",
       " 1953,\n",
       " 1747,\n",
       " 650,\n",
       " 1189,\n",
       " 866,\n",
       " 239,\n",
       " 1919,\n",
       " 1248,\n",
       " 256,\n",
       " 1008,\n",
       " 1531,\n",
       " 548,\n",
       " 151,\n",
       " 2089,\n",
       " 1499,\n",
       " 887,\n",
       " 776,\n",
       " 1612,\n",
       " 2056,\n",
       " 208,\n",
       " 755,\n",
       " 268,\n",
       " 1182,\n",
       " 107,\n",
       " 2138,\n",
       " 1165,\n",
       " 702,\n",
       " 713,\n",
       " 103,\n",
       " 2173,\n",
       " 1822,\n",
       " 1074,\n",
       " 2111,\n",
       " 527,\n",
       " 1470,\n",
       " 216,\n",
       " 1200,\n",
       " 211,\n",
       " 992,\n",
       " 1559,\n",
       " 347,\n",
       " 200,\n",
       " 1339,\n",
       " 729,\n",
       " 1386,\n",
       " 382,\n",
       " 161,\n",
       " 41,\n",
       " 1124,\n",
       " 1970,\n",
       " 2115,\n",
       " 607,\n",
       " 166,\n",
       " 1345,\n",
       " 1456,\n",
       " 709,\n",
       " 358,\n",
       " 159,\n",
       " 1762,\n",
       " 1407,\n",
       " 1609,\n",
       " 1660,\n",
       " 142,\n",
       " 2013,\n",
       " 1021,\n",
       " 19,\n",
       " 2191,\n",
       " 1341,\n",
       " 1640,\n",
       " 893,\n",
       " 1303,\n",
       " 556,\n",
       " 1156,\n",
       " 455,\n",
       " 2194,\n",
       " 285,\n",
       " 1136,\n",
       " 1826,\n",
       " 2178,\n",
       " 2101,\n",
       " 1844,\n",
       " 684,\n",
       " 1390,\n",
       " 275,\n",
       " 698,\n",
       " 1034,\n",
       " 76,\n",
       " 532,\n",
       " 917,\n",
       " 1350,\n",
       " 465,\n",
       " 794,\n",
       " 603,\n",
       " 1283,\n",
       " 1789,\n",
       " 1136,\n",
       " 12,\n",
       " 1206,\n",
       " 508,\n",
       " 592,\n",
       " 860,\n",
       " 1575,\n",
       " 254,\n",
       " 1121,\n",
       " 391,\n",
       " 361,\n",
       " 247,\n",
       " 1426,\n",
       " 48,\n",
       " 2061,\n",
       " 1574,\n",
       " 858,\n",
       " 1611,\n",
       " 104,\n",
       " 1970,\n",
       " 1335,\n",
       " 2054,\n",
       " 629,\n",
       " 1025,\n",
       " 806,\n",
       " 2196,\n",
       " 86,\n",
       " 631,\n",
       " 720,\n",
       " 1863,\n",
       " 903,\n",
       " 230,\n",
       " 595,\n",
       " 1940,\n",
       " 1828,\n",
       " 564,\n",
       " 195,\n",
       " 1600,\n",
       " 1813,\n",
       " 13,\n",
       " 997,\n",
       " 2022,\n",
       " 1439,\n",
       " 1040,\n",
       " 489,\n",
       " 1059,\n",
       " 1762,\n",
       " 203,\n",
       " 1725,\n",
       " 967,\n",
       " 296,\n",
       " 1351,\n",
       " 1792,\n",
       " 927,\n",
       " 97,\n",
       " 1966,\n",
       " 203,\n",
       " 1868,\n",
       " 2079,\n",
       " 1192,\n",
       " 501,\n",
       " 1997,\n",
       " 507,\n",
       " 994,\n",
       " 1071,\n",
       " 139,\n",
       " 283,\n",
       " 2103,\n",
       " 1152,\n",
       " 1738,\n",
       " 412,\n",
       " 1042,\n",
       " 358,\n",
       " 2029,\n",
       " 1773,\n",
       " 1141,\n",
       " 1324,\n",
       " 1519,\n",
       " 1768,\n",
       " 1025,\n",
       " 1377,\n",
       " 16,\n",
       " 1014,\n",
       " 1546,\n",
       " 292,\n",
       " 289,\n",
       " 545,\n",
       " 1466,\n",
       " 393,\n",
       " 947,\n",
       " 363,\n",
       " 896,\n",
       " 1017,\n",
       " 520,\n",
       " 1400,\n",
       " 1096,\n",
       " 1873,\n",
       " 102,\n",
       " 1611,\n",
       " 283,\n",
       " 1000,\n",
       " 841,\n",
       " 232,\n",
       " 2042,\n",
       " 1253,\n",
       " 2182,\n",
       " 134,\n",
       " 923,\n",
       " 1470,\n",
       " 931,\n",
       " 328,\n",
       " 2162,\n",
       " 473,\n",
       " 1495,\n",
       " 528,\n",
       " 2082,\n",
       " 841,\n",
       " 1282,\n",
       " 54,\n",
       " 1280,\n",
       " 1505,\n",
       " 1111,\n",
       " 334,\n",
       " 2079,\n",
       " 298,\n",
       " 1953,\n",
       " 2096,\n",
       " 285,\n",
       " 1346,\n",
       " 884,\n",
       " 1686,\n",
       " 1267,\n",
       " 2090,\n",
       " 16,\n",
       " 1766,\n",
       " 1108,\n",
       " 1636,\n",
       " 443,\n",
       " 1508,\n",
       " 346,\n",
       " 1087,\n",
       " 611,\n",
       " 2126,\n",
       " 1869,\n",
       " 1511,\n",
       " 1951,\n",
       " 1287,\n",
       " 395,\n",
       " 813,\n",
       " 1264,\n",
       " 10,\n",
       " 2180,\n",
       " 2125,\n",
       " 1714,\n",
       " 2097,\n",
       " 1794,\n",
       " 1223,\n",
       " 151,\n",
       " 815,\n",
       " 2125,\n",
       " 43,\n",
       " 304,\n",
       " 1227,\n",
       " 570,\n",
       " 184,\n",
       " 674,\n",
       " 1889,\n",
       " 902,\n",
       " 539,\n",
       " 1274,\n",
       " 688,\n",
       " 2181,\n",
       " 239,\n",
       " 667,\n",
       " 561,\n",
       " 71,\n",
       " 1283,\n",
       " 1803,\n",
       " 2112,\n",
       " 299,\n",
       " 498,\n",
       " 1017,\n",
       " 642,\n",
       " 1770,\n",
       " 1914,\n",
       " 360,\n",
       " 737,\n",
       " 857,\n",
       " 269,\n",
       " 2135,\n",
       " 2150,\n",
       " 635,\n",
       " 892,\n",
       " 2043,\n",
       " 1477,\n",
       " 1881,\n",
       " 105,\n",
       " 1033,\n",
       " 632,\n",
       " 1252,\n",
       " 2053,\n",
       " 1660,\n",
       " 1508,\n",
       " 737,\n",
       " 19,\n",
       " 1078,\n",
       " 1703,\n",
       " 1837,\n",
       " 734,\n",
       " 1268,\n",
       " 1514,\n",
       " 1850,\n",
       " 1255,\n",
       " 1121,\n",
       " 1756,\n",
       " 2101,\n",
       " 1261,\n",
       " 350,\n",
       " 1026,\n",
       " 179,\n",
       " 2027,\n",
       " 467,\n",
       " 197,\n",
       " 1135,\n",
       " 1884,\n",
       " 1966,\n",
       " 938,\n",
       " 72,\n",
       " 1153,\n",
       " 701,\n",
       " 1085,\n",
       " 27,\n",
       " 2203,\n",
       " 1253,\n",
       " 1226,\n",
       " 1120,\n",
       " 1098,\n",
       " 404,\n",
       " 1478,\n",
       " 1212,\n",
       " 690,\n",
       " 1567,\n",
       " 242,\n",
       " 1250,\n",
       " 963,\n",
       " 720,\n",
       " 1957,\n",
       " 88,\n",
       " 815,\n",
       " 968,\n",
       " 2117,\n",
       " 1738,\n",
       " 159,\n",
       " 459,\n",
       " 1033,\n",
       " 2047,\n",
       " 952,\n",
       " 1773,\n",
       " 1578,\n",
       " 228,\n",
       " 2121,\n",
       " 166,\n",
       " 1861,\n",
       " 1341,\n",
       " 11,\n",
       " 179,\n",
       " 2083,\n",
       " 1231,\n",
       " 641,\n",
       " 1427,\n",
       " 1966,\n",
       " 1083,\n",
       " 1589,\n",
       " 1413,\n",
       " 2,\n",
       " 630,\n",
       " 273,\n",
       " 1133,\n",
       " 558,\n",
       " 793,\n",
       " 125,\n",
       " 496,\n",
       " 1507,\n",
       " 1361,\n",
       " 1671,\n",
       " 515,\n",
       " 1211,\n",
       " 1788,\n",
       " 1223,\n",
       " 313,\n",
       " 243,\n",
       " 1767,\n",
       " 739,\n",
       " 1570,\n",
       " 149,\n",
       " 1951,\n",
       " 467,\n",
       " 2178,\n",
       " 843,\n",
       " 635,\n",
       " 1546,\n",
       " 552,\n",
       " 249,\n",
       " 674,\n",
       " 2080,\n",
       " 1586,\n",
       " 1513,\n",
       " 282,\n",
       " 532,\n",
       " 1185,\n",
       " 337,\n",
       " 1789,\n",
       " 1396,\n",
       " 744,\n",
       " 1584,\n",
       " 1370,\n",
       " 1122,\n",
       " 1191,\n",
       " 1178,\n",
       " 799,\n",
       " 1070,\n",
       " 1881,\n",
       " 464,\n",
       " 1724,\n",
       " 1936,\n",
       " 311,\n",
       " 2150,\n",
       " 1177,\n",
       " 792,\n",
       " 1389,\n",
       " 2114,\n",
       " 1486,\n",
       " 1480,\n",
       " 1335,\n",
       " 335,\n",
       " 1641,\n",
       " 1830,\n",
       " 477,\n",
       " 1784,\n",
       " 883,\n",
       " 1353,\n",
       " 1232,\n",
       " 1560,\n",
       " 1631,\n",
       " 460,\n",
       " 1752,\n",
       " 1410,\n",
       " 181,\n",
       " 2,\n",
       " 40,\n",
       " 2117,\n",
       " 615,\n",
       " 77,\n",
       " 335,\n",
       " 741,\n",
       " 2150,\n",
       " 2087,\n",
       " 406,\n",
       " 583,\n",
       " 1607,\n",
       " 1160,\n",
       " 952,\n",
       " 1662,\n",
       " 2080,\n",
       " 1308,\n",
       " 135,\n",
       " 1131,\n",
       " 2015,\n",
       " 47,\n",
       " 1480,\n",
       " 1460,\n",
       " 853,\n",
       " 1968,\n",
       " 477,\n",
       " 872,\n",
       " 1903,\n",
       " 1395,\n",
       " 253,\n",
       " 837,\n",
       " 219,\n",
       " 22,\n",
       " 1535,\n",
       " 1653,\n",
       " 451,\n",
       " 164,\n",
       " 784,\n",
       " 1904,\n",
       " 754,\n",
       " 1264,\n",
       " 734,\n",
       " 1322,\n",
       " 1965,\n",
       " 1985,\n",
       " 1238,\n",
       " 668,\n",
       " 798,\n",
       " 1947,\n",
       " 1285,\n",
       " 248,\n",
       " 682,\n",
       " 44,\n",
       " 454,\n",
       " 519,\n",
       " 914,\n",
       " 1287,\n",
       " 1106,\n",
       " 1631,\n",
       " 43,\n",
       " 643,\n",
       " 927,\n",
       " 1767,\n",
       " 1840,\n",
       " 1762,\n",
       " 1090,\n",
       " 343,\n",
       " 625,\n",
       " 1986,\n",
       " 703,\n",
       " 1495,\n",
       " 1841,\n",
       " 1655,\n",
       " 2175,\n",
       " 603,\n",
       " 2036,\n",
       " 1590,\n",
       " 90,\n",
       " 2033,\n",
       " 2132,\n",
       " 664,\n",
       " 518,\n",
       " 2094,\n",
       " 75,\n",
       " 1147,\n",
       " 1770,\n",
       " 2076,\n",
       " 542,\n",
       " 1771,\n",
       " 1312,\n",
       " 204,\n",
       " 1040,\n",
       " 415,\n",
       " 511,\n",
       " 1613,\n",
       " 65,\n",
       " 44,\n",
       " 1750,\n",
       " 1549,\n",
       " 1310,\n",
       " 468,\n",
       " 461,\n",
       " 236,\n",
       " 730,\n",
       " 2022,\n",
       " 522,\n",
       " 151,\n",
       " 1557,\n",
       " 1533,\n",
       " 1996,\n",
       " 1811,\n",
       " 609,\n",
       " 727,\n",
       " 2165,\n",
       " 1608,\n",
       " 882,\n",
       " 1980,\n",
       " 1580,\n",
       " 2175,\n",
       " 1780,\n",
       " 2024,\n",
       " 613,\n",
       " 883,\n",
       " 462,\n",
       " 1214,\n",
       " 8,\n",
       " 1235,\n",
       " 14,\n",
       " 1314,\n",
       " 2189,\n",
       " 909,\n",
       " 2147,\n",
       " 1605,\n",
       " 520,\n",
       " 517,\n",
       " 275,\n",
       " 1979,\n",
       " 1974,\n",
       " 746,\n",
       " 713,\n",
       " 968,\n",
       " 1421,\n",
       " 1559,\n",
       " 2206,\n",
       " 482,\n",
       " 482,\n",
       " 1943,\n",
       " 1883,\n",
       " 702,\n",
       " 713,\n",
       " 300,\n",
       " 236,\n",
       " 1774,\n",
       " 78,\n",
       " 707,\n",
       " 1344,\n",
       " 1733,\n",
       " 1259,\n",
       " 285,\n",
       " 402,\n",
       " 803,\n",
       " 577,\n",
       " 1205,\n",
       " 1076,\n",
       " 902,\n",
       " 1080,\n",
       " 282,\n",
       " 1531,\n",
       " 221,\n",
       " 1007,\n",
       " 680,\n",
       " 2184,\n",
       " 292,\n",
       " 122,\n",
       " 1136,\n",
       " 1708,\n",
       " 1456,\n",
       " 905,\n",
       " 1200,\n",
       " 89,\n",
       " 1169,\n",
       " 2187,\n",
       " 1895,\n",
       " 2132,\n",
       " 729,\n",
       " 806,\n",
       " 864,\n",
       " 1111,\n",
       " 1745,\n",
       " 934,\n",
       " 709,\n",
       " 1079,\n",
       " 57,\n",
       " 977,\n",
       " 1356,\n",
       " 780,\n",
       " 695,\n",
       " 2041,\n",
       " 2007,\n",
       " 15,\n",
       " 1024,\n",
       " 1012,\n",
       " 2083,\n",
       " 429,\n",
       " 1278,\n",
       " 173,\n",
       " 377,\n",
       " 653,\n",
       " 191,\n",
       " 1344,\n",
       " 1840,\n",
       " 2090,\n",
       " 1377,\n",
       " 745,\n",
       " 1758,\n",
       " 723,\n",
       " 31,\n",
       " 1341,\n",
       " 1379,\n",
       " 985,\n",
       " 2187,\n",
       " 1082,\n",
       " 1573,\n",
       " 639,\n",
       " 1416,\n",
       " 1298,\n",
       " 1489,\n",
       " 1189,\n",
       " 724,\n",
       " 1913,\n",
       " 119,\n",
       " 1625,\n",
       " 569,\n",
       " 2056,\n",
       " 623,\n",
       " 698,\n",
       " 1248,\n",
       " 1877,\n",
       " 918,\n",
       " 88,\n",
       " 1768,\n",
       " 342,\n",
       " 804,\n",
       " 1084,\n",
       " 364,\n",
       " 965,\n",
       " 1018,\n",
       " 1361,\n",
       " 1519,\n",
       " 892,\n",
       " 1679,\n",
       " 1708,\n",
       " 159,\n",
       " 396,\n",
       " 2132,\n",
       " 538,\n",
       " 679,\n",
       " 498,\n",
       " 1380,\n",
       " 1883,\n",
       " 1530,\n",
       " 589,\n",
       " 1875,\n",
       " 236,\n",
       " 364,\n",
       " 2099,\n",
       " 711,\n",
       " 804,\n",
       " 1780,\n",
       " 527,\n",
       " 309,\n",
       " 129,\n",
       " 864,\n",
       " 511,\n",
       " 1949,\n",
       " 1097,\n",
       " 1452,\n",
       " 1461,\n",
       " 418,\n",
       " 1581,\n",
       " 1534,\n",
       " 573,\n",
       " 1123,\n",
       " 1232,\n",
       " 795,\n",
       " 911,\n",
       " 1838,\n",
       " 301,\n",
       " 1643,\n",
       " 1481,\n",
       " 1984,\n",
       " 822,\n",
       " 5,\n",
       " 1718,\n",
       " 2208,\n",
       " 771,\n",
       " 970,\n",
       " 1037,\n",
       " 326,\n",
       " 1237,\n",
       " 569,\n",
       " 837,\n",
       " 2183,\n",
       " 31,\n",
       " 1176,\n",
       " 1098,\n",
       " 753,\n",
       " 2121,\n",
       " 87,\n",
       " 2079,\n",
       " 1104,\n",
       " 1155,\n",
       " 1491,\n",
       " 1711,\n",
       " 1574,\n",
       " 521,\n",
       " 161,\n",
       " 430,\n",
       " 1469,\n",
       " 927,\n",
       " 1270,\n",
       " 1908,\n",
       " 65,\n",
       " 395,\n",
       " 126,\n",
       " 2048,\n",
       " 258,\n",
       " 27,\n",
       " 1599,\n",
       " 1414,\n",
       " 464,\n",
       " 1278,\n",
       " 456,\n",
       " 370,\n",
       " 1866,\n",
       " 1902,\n",
       " 2030,\n",
       " 2135,\n",
       " 1067,\n",
       " 1143,\n",
       " 872,\n",
       " 718,\n",
       " 1420,\n",
       " 1983,\n",
       " 1170,\n",
       " 1989,\n",
       " 1332,\n",
       " 63,\n",
       " 1229,\n",
       " 1188,\n",
       " 1804,\n",
       " 1367,\n",
       " 1534,\n",
       " 1759,\n",
       " 705,\n",
       " 507,\n",
       " 14,\n",
       " 451,\n",
       " 902,\n",
       " 888,\n",
       " 836,\n",
       " 2136,\n",
       " 1884,\n",
       " 2082,\n",
       " 1968,\n",
       " 1252,\n",
       " 106,\n",
       " 1767,\n",
       " 1829,\n",
       " 900,\n",
       " 2203,\n",
       " 1484,\n",
       " 272,\n",
       " 365,\n",
       " 1434,\n",
       " 863,\n",
       " 728,\n",
       " 751,\n",
       " 2075,\n",
       " 455,\n",
       " 1873,\n",
       " 306,\n",
       " 836,\n",
       " 814,\n",
       " 1783,\n",
       " 1007,\n",
       " 476,\n",
       " 2119,\n",
       " 1664,\n",
       " 1874,\n",
       " 271,\n",
       " 155,\n",
       " 205,\n",
       " 523,\n",
       " 1351,\n",
       " 1006,\n",
       " 1065,\n",
       " 174,\n",
       " 1537,\n",
       " 1861,\n",
       " 1371,\n",
       " 73,\n",
       " 1624,\n",
       " 283,\n",
       " 1515,\n",
       " 1780,\n",
       " 1805,\n",
       " 584,\n",
       " 1941,\n",
       " 828,\n",
       " 949,\n",
       " 1787,\n",
       " 151,\n",
       " 542,\n",
       " 131,\n",
       " 1145,\n",
       " 2101,\n",
       " 1101,\n",
       " 415,\n",
       " 315,\n",
       " 1114,\n",
       " 428,\n",
       " 1844,\n",
       " 809,\n",
       " 702,\n",
       " 31,\n",
       " 472,\n",
       " 1998,\n",
       " 1349,\n",
       " 80,\n",
       " 2056,\n",
       " 1822,\n",
       " 1943,\n",
       " 1929,\n",
       " 1827,\n",
       " 876,\n",
       " 126,\n",
       " 1725,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1403])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miniter = mini.filter(lambda example: tf_is_in_set(example[\"measurement_id\"][0], tf.constant([1970, 1403], dtype=tf.int64))).make_one_shot_iterator()\n",
    "miniter.get_next()\n",
    "miniter.get_next()[\"measurement_id\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batched_dataset(filenames, batch_size, m_ids, max_queue_size=10,  n_process=4, is_train=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=1, num_parallel_calls=1)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda example: tf_is_in_set(example[\"measurement_id\"][0], tf.constant(m_ids, dtype=tf.int64)))\n",
    "    dataset = dataset.map(map_example_to_simple)\n",
    "    dataset = dataset.filter(lambda x, y: tf.not_equal(y[0], -1))\n",
    "#     dataset = dataset.filter(lambda x, y: tf.math.reduce_std(x) > 0.05)\n",
    "#     dataset = dataset.filter(lambda x, y: tf.not_equal(y[1], -1))\n",
    "#     dataset = dataset.filter(lambda x, y: tf.not_equal(y[2], -1))\n",
    "\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(2056)\n",
    "#     dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if is_train:\n",
    "        dataset = dataset.prefetch(max_queue_size)\n",
    "    else:\n",
    "        dataset = dataset.prefetch(int(max_queue_size/4)) #store a lot less for the other sets to avoid wasting memory\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels =  pd.read_csv(\"/home/ms994/beat_pd/data/cis-pd/data_labels/CIS-PD_Training_Data_IDs_Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mid, test_mid = train_test_split(labels.measurement_id.unique(), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mid, valid_mid = train_test_split(train_mid, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mid = sorted(labels.measurement_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices  = [all_mid.index(train_m) for train_m in train_mid]\n",
    "valid_indices  = [all_mid.index(train_m) for train_m in valid_mid]\n",
    "test_indices  = [all_mid.index(train_m) for train_m in test_mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=256)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['measurement_id'][0])\n",
    "train_debug = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = train_debug.take(1000).make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_id = [] \n",
    "on_off = []\n",
    "for i in iterator:\n",
    "    m_id.append(i[1][1].numpy())\n",
    "    on_off.append(i[1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([m_id, on_off]).T.groupby(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# (np.hstack(all_m_id) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 1\n",
    "num_lin_layers = 2\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(16, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.CuDNNLSTM(256, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(200)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "# #tremor\n",
    "# x = x_shared_flattened \n",
    "# for k in range(num_lin_layers):\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Dense(100)(x)\n",
    "#     x = tf.keras.layers.LeakyReLU()(x)\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = tf.keras.layers.Dense(1)(x)\n",
    "# x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "# #montage classify\n",
    "# x = x_shared_flattened \n",
    "# for k in range(num_lin_layers):\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Dense(100)(x)\n",
    "#     x = tf.keras.layers.LeakyReLU()(x)\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = tf.keras.layers.Dense(1)(x)\n",
    "# x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 1500, 3)           12        \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1500, 16)          160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 1500, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 750, 16)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 750, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 750, 16)           784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 750, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 375, 16)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 375, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 375, 16)           784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 375, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 187, 16)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 187, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 187, 16)           784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 187, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 93, 16)            64        \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 93, 16)            784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 46, 16)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 46, 16)            64        \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 46, 256)           280576    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 46, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_encoder_lstm (Flatte (None, 11776)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 200)               2355400   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               51456     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "on_off (ReLU)                (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,758,933\n",
      "Trainable params: 2,757,855\n",
      "Non-trainable params: 1,078\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=[\"mean_squared_error\" ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.7004\n",
      "Epoch 00001: val_loss improved from inf to 1.58099, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.7003 - val_loss: 1.5810\n",
      "Epoch 2/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.5864\n",
      "Epoch 00002: val_loss did not improve from 1.58099\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.5879 - val_loss: 1.9379\n",
      "Epoch 3/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.5629\n",
      "Epoch 00003: val_loss did not improve from 1.58099\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.5620 - val_loss: 1.6239\n",
      "Epoch 4/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4574\n",
      "Epoch 00004: val_loss improved from 1.58099 to 1.50739, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.4574 - val_loss: 1.5074\n",
      "Epoch 5/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.4407\n",
      "Epoch 00005: val_loss improved from 1.50739 to 1.47605, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.4418 - val_loss: 1.4760\n",
      "Epoch 6/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4394\n",
      "Epoch 00006: val_loss did not improve from 1.47605\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.4396 - val_loss: 1.4792\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4343\n",
      "Epoch 00007: val_loss improved from 1.47605 to 1.42835, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.4344 - val_loss: 1.4284\n",
      "Epoch 8/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4265\n",
      "Epoch 00008: val_loss did not improve from 1.42835\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.4264 - val_loss: 1.4551\n",
      "Epoch 9/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4211\n",
      "Epoch 00009: val_loss did not improve from 1.42835\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.4211 - val_loss: 1.4643\n",
      "Epoch 10/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4155\n",
      "Epoch 00010: val_loss did not improve from 1.42835\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.4149 - val_loss: 1.4349\n",
      "Epoch 11/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3995\n",
      "Epoch 00011: val_loss did not improve from 1.42835\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.3993 - val_loss: 1.4300\n",
      "Epoch 12/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3922\n",
      "Epoch 00012: val_loss improved from 1.42835 to 1.42203, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.3923 - val_loss: 1.4220\n",
      "Epoch 13/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3770\n",
      "Epoch 00013: val_loss did not improve from 1.42203\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.3770 - val_loss: 1.4256\n",
      "Epoch 14/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3655\n",
      "Epoch 00014: val_loss improved from 1.42203 to 1.40778, saving model to /n/scratch2/ms994/cnnlstm1.h5\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.3654 - val_loss: 1.4078\n",
      "Epoch 15/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3503\n",
      "Epoch 00015: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.3496 - val_loss: 1.5141\n",
      "Epoch 16/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.3395\n",
      "Epoch 00016: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.3401 - val_loss: 1.4594\n",
      "Epoch 17/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3238\n",
      "Epoch 00017: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.3244 - val_loss: 1.5009\n",
      "Epoch 18/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3165\n",
      "Epoch 00018: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.3173 - val_loss: 1.4185\n",
      "Epoch 19/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2998\n",
      "Epoch 00019: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.2994 - val_loss: 1.4375\n",
      "Epoch 20/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2899\n",
      "Epoch 00020: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.2899 - val_loss: 1.4146\n",
      "Epoch 21/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.2825\n",
      "Epoch 00021: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.2823 - val_loss: 1.4897\n",
      "Epoch 22/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2670\n",
      "Epoch 00022: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.2667 - val_loss: 1.5801\n",
      "Epoch 23/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.2492\n",
      "Epoch 00023: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.2491 - val_loss: 1.4184\n",
      "Epoch 24/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.2302\n",
      "Epoch 00024: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 1.2292 - val_loss: 1.4213\n",
      "Epoch 25/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.1619\n",
      "Epoch 00025: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.1616 - val_loss: 1.4478\n",
      "Epoch 26/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1375\n",
      "Epoch 00026: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.1373 - val_loss: 1.5028\n",
      "Epoch 27/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1303\n",
      "Epoch 00027: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.1300 - val_loss: 1.4647\n",
      "Epoch 28/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.1113\n",
      "Epoch 00028: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.1118 - val_loss: 1.4663\n",
      "Epoch 29/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0989\n",
      "Epoch 00029: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0991 - val_loss: 1.4739\n",
      "Epoch 30/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0936\n",
      "Epoch 00030: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0932 - val_loss: 1.4895\n",
      "Epoch 31/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0809\n",
      "Epoch 00031: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0809 - val_loss: 1.4935\n",
      "Epoch 32/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0731\n",
      "Epoch 00032: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0729 - val_loss: 1.4836\n",
      "Epoch 33/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0590\n",
      "Epoch 00033: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 1.0589 - val_loss: 1.5042\n",
      "Epoch 34/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0518\n",
      "Epoch 00034: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.0513 - val_loss: 1.5120\n",
      "Epoch 35/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0411\n",
      "Epoch 00035: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0408 - val_loss: 1.5139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0286\n",
      "Epoch 00036: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0284 - val_loss: 1.5189\n",
      "Epoch 37/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0280\n",
      "Epoch 00037: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0284 - val_loss: 1.5217\n",
      "Epoch 38/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0326\n",
      "Epoch 00038: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0330 - val_loss: 1.5126\n",
      "Epoch 39/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0321\n",
      "Epoch 00039: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0325 - val_loss: 1.5110\n",
      "Epoch 40/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0256\n",
      "Epoch 00040: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0255 - val_loss: 1.5115\n",
      "Epoch 41/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0230\n",
      "Epoch 00041: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0235 - val_loss: 1.5208\n",
      "Epoch 42/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0252\n",
      "Epoch 00042: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0251 - val_loss: 1.5210\n",
      "Epoch 43/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0252\n",
      "Epoch 00043: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0256 - val_loss: 1.5214\n",
      "Epoch 44/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0220\n",
      "Epoch 00044: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.0226 - val_loss: 1.5130\n",
      "Epoch 45/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0203\n",
      "Epoch 00045: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0213 - val_loss: 1.5025\n",
      "Epoch 46/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0212\n",
      "Epoch 00046: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0207 - val_loss: 1.5181\n",
      "Epoch 47/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0215\n",
      "Epoch 00047: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0215 - val_loss: 1.5117\n",
      "Epoch 48/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0174\n",
      "Epoch 00048: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.0171 - val_loss: 1.5192\n",
      "Epoch 49/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0229\n",
      "Epoch 00049: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0231 - val_loss: 1.5218\n",
      "Epoch 50/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0179\n",
      "Epoch 00050: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 1.0179 - val_loss: 1.5229\n",
      "Epoch 51/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0182\n",
      "Epoch 00051: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0181 - val_loss: 1.5125\n",
      "Epoch 52/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0151\n",
      "Epoch 00052: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0150 - val_loss: 1.5169\n",
      "Epoch 53/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0207\n",
      "Epoch 00053: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0208 - val_loss: 1.5113\n",
      "Epoch 54/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0184\n",
      "Epoch 00054: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0183 - val_loss: 1.5188\n",
      "Epoch 55/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0187\n",
      "Epoch 00055: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0185 - val_loss: 1.5223\n",
      "Epoch 56/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0189\n",
      "Epoch 00056: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0187 - val_loss: 1.5336\n",
      "Epoch 57/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0227\n",
      "Epoch 00057: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0224 - val_loss: 1.5272\n",
      "Epoch 58/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0158\n",
      "Epoch 00058: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0157 - val_loss: 1.5114\n",
      "Epoch 59/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0148\n",
      "Epoch 00059: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0147 - val_loss: 1.5226\n",
      "Epoch 60/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0197\n",
      "Epoch 00060: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0199 - val_loss: 1.5132\n",
      "Epoch 61/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0195\n",
      "Epoch 00061: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0197 - val_loss: 1.5243\n",
      "Epoch 62/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0178\n",
      "Epoch 00062: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0177 - val_loss: 1.5254\n",
      "Epoch 63/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0168\n",
      "Epoch 00063: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0168 - val_loss: 1.5265\n",
      "Epoch 64/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0164\n",
      "Epoch 00064: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0163 - val_loss: 1.5200\n",
      "Epoch 65/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0274\n",
      "Epoch 00065: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0269 - val_loss: 1.5135\n",
      "Epoch 66/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0178\n",
      "Epoch 00066: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 1.0179 - val_loss: 1.5106\n",
      "Epoch 67/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0116\n",
      "Epoch 00067: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.0115 - val_loss: 1.5182\n",
      "Epoch 68/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0195\n",
      "Epoch 00068: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0199 - val_loss: 1.5174\n",
      "Epoch 69/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0172\n",
      "Epoch 00069: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0175 - val_loss: 1.5244\n",
      "Epoch 70/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0159\n",
      "Epoch 00070: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0163 - val_loss: 1.5218\n",
      "Epoch 71/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0203\n",
      "Epoch 00071: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0203 - val_loss: 1.5126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0249\n",
      "Epoch 00072: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0249 - val_loss: 1.5249\n",
      "Epoch 73/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0214\n",
      "Epoch 00073: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0211 - val_loss: 1.5195\n",
      "Epoch 74/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0143\n",
      "Epoch 00074: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0145 - val_loss: 1.5221\n",
      "Epoch 75/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0164\n",
      "Epoch 00075: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0162 - val_loss: 1.5335\n",
      "Epoch 76/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0222\n",
      "Epoch 00076: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0221 - val_loss: 1.5265\n",
      "Epoch 77/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0191\n",
      "Epoch 00077: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0197 - val_loss: 1.5139\n",
      "Epoch 78/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0142\n",
      "Epoch 00078: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0151 - val_loss: 1.5139\n",
      "Epoch 79/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0192\n",
      "Epoch 00079: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0192 - val_loss: 1.5200\n",
      "Epoch 80/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0224\n",
      "Epoch 00080: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0225 - val_loss: 1.5206\n",
      "Epoch 81/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0189\n",
      "Epoch 00081: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0189 - val_loss: 1.5172\n",
      "Epoch 82/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0188\n",
      "Epoch 00082: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0191 - val_loss: 1.5246\n",
      "Epoch 83/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0145\n",
      "Epoch 00083: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0142 - val_loss: 1.5237\n",
      "Epoch 84/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0231\n",
      "Epoch 00084: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0228 - val_loss: 1.5083\n",
      "Epoch 85/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0145\n",
      "Epoch 00085: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0143 - val_loss: 1.5198\n",
      "Epoch 86/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0158\n",
      "Epoch 00086: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0155 - val_loss: 1.5132\n",
      "Epoch 87/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0209\n",
      "Epoch 00087: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0211 - val_loss: 1.5205\n",
      "Epoch 88/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0203\n",
      "Epoch 00088: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0197 - val_loss: 1.5257\n",
      "Epoch 89/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0208\n",
      "Epoch 00089: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0205 - val_loss: 1.5314\n",
      "Epoch 90/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0180\n",
      "Epoch 00090: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0184 - val_loss: 1.5257\n",
      "Epoch 91/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0171\n",
      "Epoch 00091: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0170 - val_loss: 1.5163\n",
      "Epoch 92/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0203\n",
      "Epoch 00092: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0200 - val_loss: 1.5207\n",
      "Epoch 93/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0189\n",
      "Epoch 00093: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0193 - val_loss: 1.5150\n",
      "Epoch 94/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0144\n",
      "Epoch 00094: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0147 - val_loss: 1.5184\n",
      "Epoch 95/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0195\n",
      "Epoch 00095: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0204 - val_loss: 1.5292\n",
      "Epoch 96/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0199\n",
      "Epoch 00096: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0203 - val_loss: 1.5288\n",
      "Epoch 97/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0143\n",
      "Epoch 00097: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0144 - val_loss: 1.5100\n",
      "Epoch 98/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0219\n",
      "Epoch 00098: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0220 - val_loss: 1.5146\n",
      "Epoch 99/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0220\n",
      "Epoch 00099: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0219 - val_loss: 1.5138\n",
      "Epoch 100/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0150\n",
      "Epoch 00100: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0145 - val_loss: 1.5161\n",
      "Epoch 101/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0163\n",
      "Epoch 00101: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0170 - val_loss: 1.5235\n",
      "Epoch 102/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0160\n",
      "Epoch 00102: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0162 - val_loss: 1.5251\n",
      "Epoch 103/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0168\n",
      "Epoch 00103: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0166 - val_loss: 1.5188\n",
      "Epoch 104/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0190\n",
      "Epoch 00104: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0188 - val_loss: 1.5085\n",
      "Epoch 105/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0232\n",
      "Epoch 00105: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0226 - val_loss: 1.5278\n",
      "Epoch 106/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0246\n",
      "Epoch 00106: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0248 - val_loss: 1.5218\n",
      "Epoch 107/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0172\n",
      "Epoch 00107: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0174 - val_loss: 1.5231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0125\n",
      "Epoch 00108: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0124 - val_loss: 1.5310\n",
      "Epoch 109/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0156\n",
      "Epoch 00109: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0149 - val_loss: 1.5296\n",
      "Epoch 110/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0217\n",
      "Epoch 00110: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0216 - val_loss: 1.5090\n",
      "Epoch 111/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0158\n",
      "Epoch 00111: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0162 - val_loss: 1.5151\n",
      "Epoch 112/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0165\n",
      "Epoch 00112: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0168 - val_loss: 1.5183\n",
      "Epoch 113/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0202\n",
      "Epoch 00113: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0207 - val_loss: 1.5204\n",
      "Epoch 114/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0229\n",
      "Epoch 00114: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0226 - val_loss: 1.5249\n",
      "Epoch 115/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0211\n",
      "Epoch 00115: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0208 - val_loss: 1.5256\n",
      "Epoch 116/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0130\n",
      "Epoch 00116: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.0126 - val_loss: 1.5219\n",
      "Epoch 117/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0207\n",
      "Epoch 00117: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0206 - val_loss: 1.5013\n",
      "Epoch 118/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0198\n",
      "Epoch 00118: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0195 - val_loss: 1.5193\n",
      "Epoch 119/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0149\n",
      "Epoch 00119: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0157 - val_loss: 1.5137\n",
      "Epoch 120/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0156\n",
      "Epoch 00120: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0160 - val_loss: 1.5177\n",
      "Epoch 121/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0241\n",
      "Epoch 00121: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0235 - val_loss: 1.5302\n",
      "Epoch 122/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0180\n",
      "Epoch 00122: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0182 - val_loss: 1.5339\n",
      "Epoch 123/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0201\n",
      "Epoch 00123: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0208 - val_loss: 1.5222\n",
      "Epoch 124/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0151\n",
      "Epoch 00124: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0149 - val_loss: 1.5175\n",
      "Epoch 125/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0208\n",
      "Epoch 00125: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0203 - val_loss: 1.5196\n",
      "Epoch 126/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0213\n",
      "Epoch 00126: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0204 - val_loss: 1.5159\n",
      "Epoch 127/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0134\n",
      "Epoch 00127: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0137 - val_loss: 1.5244\n",
      "Epoch 128/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0149\n",
      "Epoch 00128: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0152 - val_loss: 1.5292\n",
      "Epoch 129/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0239\n",
      "Epoch 00129: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0238 - val_loss: 1.5252\n",
      "Epoch 130/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0191\n",
      "Epoch 00130: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0189 - val_loss: 1.5091\n",
      "Epoch 131/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0202\n",
      "Epoch 00131: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0201 - val_loss: 1.5160\n",
      "Epoch 132/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0181\n",
      "Epoch 00132: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0184 - val_loss: 1.5089\n",
      "Epoch 133/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0201\n",
      "Epoch 00133: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0192 - val_loss: 1.5203\n",
      "Epoch 134/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0197\n",
      "Epoch 00134: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0204 - val_loss: 1.5239\n",
      "Epoch 135/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0108\n",
      "Epoch 00135: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0112 - val_loss: 1.5236\n",
      "Epoch 136/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0142\n",
      "Epoch 00136: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0138 - val_loss: 1.5120\n",
      "Epoch 137/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0209\n",
      "Epoch 00137: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0204 - val_loss: 1.5178\n",
      "Epoch 138/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0230\n",
      "Epoch 00138: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0230 - val_loss: 1.5223\n",
      "Epoch 139/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0212\n",
      "Epoch 00139: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0214 - val_loss: 1.5210\n",
      "Epoch 140/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0201\n",
      "Epoch 00140: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0200 - val_loss: 1.5224\n",
      "Epoch 141/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0176\n",
      "Epoch 00141: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0179 - val_loss: 1.5359\n",
      "Epoch 142/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0183\n",
      "Epoch 00142: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0173 - val_loss: 1.5201\n",
      "Epoch 143/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0155\n",
      "Epoch 00143: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0157 - val_loss: 1.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0196\n",
      "Epoch 00144: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0196 - val_loss: 1.5206\n",
      "Epoch 145/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0184\n",
      "Epoch 00145: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0187 - val_loss: 1.5190\n",
      "Epoch 146/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0167\n",
      "Epoch 00146: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0172 - val_loss: 1.5211\n",
      "Epoch 147/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0210\n",
      "Epoch 00147: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0213 - val_loss: 1.5270\n",
      "Epoch 148/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0231\n",
      "Epoch 00148: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0232 - val_loss: 1.5216\n",
      "Epoch 149/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0155\n",
      "Epoch 00149: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0151 - val_loss: 1.5159\n",
      "Epoch 150/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0183\n",
      "Epoch 00150: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0182 - val_loss: 1.5121\n",
      "Epoch 151/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0172\n",
      "Epoch 00151: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0170 - val_loss: 1.5146\n",
      "Epoch 152/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0213\n",
      "Epoch 00152: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0211 - val_loss: 1.5158\n",
      "Epoch 153/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0148\n",
      "Epoch 00153: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0143 - val_loss: 1.5214\n",
      "Epoch 154/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0193\n",
      "Epoch 00154: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0191 - val_loss: 1.5325\n",
      "Epoch 155/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0204\n",
      "Epoch 00155: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0204 - val_loss: 1.5291\n",
      "Epoch 156/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0219\n",
      "Epoch 00156: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0219 - val_loss: 1.5152\n",
      "Epoch 157/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0159\n",
      "Epoch 00157: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0158 - val_loss: 1.5233\n",
      "Epoch 158/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0183\n",
      "Epoch 00158: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0180 - val_loss: 1.5166\n",
      "Epoch 159/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0224\n",
      "Epoch 00159: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0214 - val_loss: 1.5178\n",
      "Epoch 160/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0173\n",
      "Epoch 00160: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0173 - val_loss: 1.5259\n",
      "Epoch 161/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0153\n",
      "Epoch 00161: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0157 - val_loss: 1.5253\n",
      "Epoch 162/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0176\n",
      "Epoch 00162: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0175 - val_loss: 1.5187\n",
      "Epoch 163/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0199\n",
      "Epoch 00163: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0200 - val_loss: 1.5176\n",
      "Epoch 164/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0198\n",
      "Epoch 00164: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.0192 - val_loss: 1.5160\n",
      "Epoch 165/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0180\n",
      "Epoch 00165: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0182 - val_loss: 1.5163\n",
      "Epoch 166/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0157\n",
      "Epoch 00166: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0149 - val_loss: 1.5140\n",
      "Epoch 167/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0246\n",
      "Epoch 00167: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0252 - val_loss: 1.5252\n",
      "Epoch 168/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0157\n",
      "Epoch 00168: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0157 - val_loss: 1.5235\n",
      "Epoch 169/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0142\n",
      "Epoch 00169: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0140 - val_loss: 1.5081\n",
      "Epoch 170/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0176\n",
      "Epoch 00170: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0176 - val_loss: 1.5219\n",
      "Epoch 171/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0254\n",
      "Epoch 00171: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0245 - val_loss: 1.5225\n",
      "Epoch 172/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0212\n",
      "Epoch 00172: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0215 - val_loss: 1.5228\n",
      "Epoch 173/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0156\n",
      "Epoch 00173: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0163 - val_loss: 1.5261\n",
      "Epoch 174/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0199\n",
      "Epoch 00174: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0197 - val_loss: 1.5342\n",
      "Epoch 175/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0222\n",
      "Epoch 00175: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0211 - val_loss: 1.5166\n",
      "Epoch 176/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0151\n",
      "Epoch 00176: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0149 - val_loss: 1.5069\n",
      "Epoch 177/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0131\n",
      "Epoch 00177: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0127 - val_loss: 1.5207\n",
      "Epoch 178/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0229\n",
      "Epoch 00178: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0230 - val_loss: 1.5236\n",
      "Epoch 179/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0235\n",
      "Epoch 00179: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.0236 - val_loss: 1.5158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0147\n",
      "Epoch 00180: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0148 - val_loss: 1.5268\n",
      "Epoch 181/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0241\n",
      "Epoch 00181: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0237 - val_loss: 1.5244\n",
      "Epoch 182/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0178\n",
      "Epoch 00182: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0185 - val_loss: 1.5084\n",
      "Epoch 183/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0198\n",
      "Epoch 00183: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.0194 - val_loss: 1.5150\n",
      "Epoch 184/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0126\n",
      "Epoch 00184: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0126 - val_loss: 1.5140\n",
      "Epoch 185/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0188\n",
      "Epoch 00185: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0191 - val_loss: 1.5156\n",
      "Epoch 186/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0186\n",
      "Epoch 00186: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0190 - val_loss: 1.5230\n",
      "Epoch 187/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0207\n",
      "Epoch 00187: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0205 - val_loss: 1.5321\n",
      "Epoch 188/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0177\n",
      "Epoch 00188: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0179 - val_loss: 1.5273\n",
      "Epoch 189/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0220\n",
      "Epoch 00189: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0222 - val_loss: 1.5125\n",
      "Epoch 190/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0181\n",
      "Epoch 00190: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0182 - val_loss: 1.5228\n",
      "Epoch 191/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0187\n",
      "Epoch 00191: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0184 - val_loss: 1.5212\n",
      "Epoch 192/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0184\n",
      "Epoch 00192: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0180 - val_loss: 1.5172\n",
      "Epoch 193/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0175\n",
      "Epoch 00193: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.0175 - val_loss: 1.5296\n",
      "Epoch 194/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0176\n",
      "Epoch 00194: val_loss did not improve from 1.40778\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0180 - val_loss: 1.5300\n",
      "Epoch 195/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0180\n",
      "Epoch 00195: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0185 - val_loss: 1.5115\n",
      "Epoch 196/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0142\n",
      "Epoch 00196: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0142 - val_loss: 1.5170\n",
      "Epoch 197/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0233\n",
      "Epoch 00197: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.0238 - val_loss: 1.5110\n",
      "Epoch 198/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0221\n",
      "Epoch 00198: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.0220 - val_loss: 1.5189\n",
      "Epoch 199/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0133\n",
      "Epoch 00199: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0127 - val_loss: 1.5180\n",
      "Epoch 200/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0177\n",
      "Epoch 00200: val_loss did not improve from 1.40778\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.0185 - val_loss: 1.5285\n"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm1.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=True)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(history.history, open(\"history.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 15s 147ms/step - loss: 1.6398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6397531282901765"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbf09bba748>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"train\", \"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn model with multiple tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)\n",
    "\n",
    "def map_example_to_simple_train(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)\n",
    "\n",
    "def get_batched_dataset(filenames, batch_size, m_ids, max_queue_size=10,  n_process=4, map_example=None):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=n_process)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda example: tf_is_in_set(example[\"measurement_id\"], tf.constant(m_ids, dtype=tf.int64)))\n",
    "#     if is_train:\n",
    "#         dataset = dataset.map(map_example_to_simple_train, num_parallel_calls=n_process)\n",
    "#     else:\n",
    "    dataset = dataset.map(map_example, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda x, y: tf.not_equal(y[0], -1))\n",
    "#     dataset = dataset.filter(lambda x, y: tf.math.reduce_std(x) > 0.05)\n",
    "    dataset = dataset.filter(lambda x, y: tf.not_equal(y[1], -1))\n",
    "    dataset = dataset.filter(lambda x, y: tf.not_equal(y[2], -1))\n",
    "\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "#     if is_train:\n",
    "    dataset = dataset.shuffle(2056)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "#     if is_train:\n",
    "    dataset = dataset.prefetch(max_queue_size)\n",
    "#     else:\n",
    "#         dataset = dataset.prefetch(int(max_queue_size/4)) #store a lot less for the other sets to avoid wasting memory\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 1\n",
    "num_lin_layers = 2\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(16, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.CuDNNLSTM(256, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(200)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off, x_dyskinesia, x_tremor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 1500, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 1500, 3)      12          input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1500, 16)     160         batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 1500, 16)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 750, 16)      0           leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 750, 16)      64          max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 750, 16)      784         batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 750, 16)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 375, 16)      0           leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 375, 16)      64          max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 375, 16)      784         batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 375, 16)      0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 187, 16)      0           leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 187, 16)      64          max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 187, 16)      784         batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 187, 16)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 93, 16)       0           leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 93, 16)       64          max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 93, 16)       784         batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 93, 16)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 46, 16)       0           leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 46, 16)       64          max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)        (None, 46, 256)      280576      batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 46, 256)      0           cu_dnnlstm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_encoder_lstm (Flatten)  (None, 11776)        0           leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 200)          2355400     flatten_encoder_lstm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 200)          0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 200)          0           leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 200)          800         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 200)          800         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 200)          800         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 256)          51456       batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 100)          20100       batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 100)          20100       batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 256)          0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 100)          0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 100)          0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256)          0           leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 100)          0           leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 100)          0           leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 256)          1024        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 100)          400         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 100)          400         dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 256)          65792       batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 100)          10100       batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 100)          10100       batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 256)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 100)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 100)          0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 256)          0           leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 100)          0           leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 100)          0           leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            257         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            101         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            101         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 1)            0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 1)            0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 1)            0           dense_51[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,821,935\n",
      "Trainable params: 2,819,657\n",
      "Non-trainable params: 2,278\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=[\"mean_squared_error\", \"mean_squared_error\",\"mean_squared_error\", ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128, map_example=map_example_to_simple)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=256, map_example=map_example_to_simple)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=256, map_example=map_example_to_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7351 - on_off_loss: 1.9878 - dyskinesia_loss: 0.8362 - tremor_loss: 0.9110\n",
      "Epoch 00001: val_loss improved from inf to 3.95291, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 3.7372 - on_off_loss: 1.9885 - dyskinesia_loss: 0.8370 - tremor_loss: 0.9117 - val_loss: 3.9529 - val_on_off_loss: 1.7510 - val_dyskinesia_loss: 1.0070 - val_tremor_loss: 1.1949\n",
      "Epoch 2/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4773 - on_off_loss: 1.8517 - dyskinesia_loss: 0.7781 - tremor_loss: 0.8474\n",
      "Epoch 00002: val_loss improved from 3.95291 to 3.60927, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 3.4761 - on_off_loss: 1.8508 - dyskinesia_loss: 0.7780 - tremor_loss: 0.8473 - val_loss: 3.6093 - val_on_off_loss: 1.7745 - val_dyskinesia_loss: 0.9310 - val_tremor_loss: 0.9037\n",
      "Epoch 3/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.2491 - on_off_loss: 1.7307 - dyskinesia_loss: 0.7251 - tremor_loss: 0.7933\n",
      "Epoch 00003: val_loss improved from 3.60927 to 3.46086, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 3.2491 - on_off_loss: 1.7311 - dyskinesia_loss: 0.7249 - tremor_loss: 0.7931 - val_loss: 3.4609 - val_on_off_loss: 1.7013 - val_dyskinesia_loss: 0.8596 - val_tremor_loss: 0.9000\n",
      "Epoch 4/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.0985 - on_off_loss: 1.6702 - dyskinesia_loss: 0.6763 - tremor_loss: 0.7519\n",
      "Epoch 00004: val_loss improved from 3.46086 to 3.33890, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 3.0983 - on_off_loss: 1.6698 - dyskinesia_loss: 0.6763 - tremor_loss: 0.7521 - val_loss: 3.3389 - val_on_off_loss: 1.6178 - val_dyskinesia_loss: 0.8743 - val_tremor_loss: 0.8468\n",
      "Epoch 5/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.9519 - on_off_loss: 1.6147 - dyskinesia_loss: 0.6346 - tremor_loss: 0.7026\n",
      "Epoch 00005: val_loss did not improve from 3.33890\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 2.9509 - on_off_loss: 1.6143 - dyskinesia_loss: 0.6343 - tremor_loss: 0.7024 - val_loss: 3.3967 - val_on_off_loss: 1.6757 - val_dyskinesia_loss: 0.8861 - val_tremor_loss: 0.8348\n",
      "Epoch 6/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.8460 - on_off_loss: 1.5545 - dyskinesia_loss: 0.6147 - tremor_loss: 0.6767\n",
      "Epoch 00006: val_loss improved from 3.33890 to 3.31138, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 2.8456 - on_off_loss: 1.5546 - dyskinesia_loss: 0.6143 - tremor_loss: 0.6767 - val_loss: 3.3114 - val_on_off_loss: 1.6496 - val_dyskinesia_loss: 0.8399 - val_tremor_loss: 0.8220\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.7355 - on_off_loss: 1.4957 - dyskinesia_loss: 0.5887 - tremor_loss: 0.6511\n",
      "Epoch 00007: val_loss improved from 3.31138 to 3.27607, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 2.7361 - on_off_loss: 1.4964 - dyskinesia_loss: 0.5887 - tremor_loss: 0.6510 - val_loss: 3.2761 - val_on_off_loss: 1.6284 - val_dyskinesia_loss: 0.8548 - val_tremor_loss: 0.7928\n",
      "Epoch 8/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.6205 - on_off_loss: 1.4255 - dyskinesia_loss: 0.5655 - tremor_loss: 0.6294\n",
      "Epoch 00008: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 2.6204 - on_off_loss: 1.4260 - dyskinesia_loss: 0.5653 - tremor_loss: 0.6291 - val_loss: 3.3714 - val_on_off_loss: 1.6696 - val_dyskinesia_loss: 0.8679 - val_tremor_loss: 0.8339\n",
      "Epoch 9/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.4979 - on_off_loss: 1.3643 - dyskinesia_loss: 0.5347 - tremor_loss: 0.5989\n",
      "Epoch 00009: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 2.4978 - on_off_loss: 1.3645 - dyskinesia_loss: 0.5346 - tremor_loss: 0.5987 - val_loss: 3.3873 - val_on_off_loss: 1.7064 - val_dyskinesia_loss: 0.8617 - val_tremor_loss: 0.8192\n",
      "Epoch 10/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.3786 - on_off_loss: 1.2958 - dyskinesia_loss: 0.5107 - tremor_loss: 0.5720\n",
      "Epoch 00010: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 2.3787 - on_off_loss: 1.2958 - dyskinesia_loss: 0.5108 - tremor_loss: 0.5721 - val_loss: 3.4513 - val_on_off_loss: 1.7573 - val_dyskinesia_loss: 0.8649 - val_tremor_loss: 0.8290\n",
      "Epoch 11/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.2455 - on_off_loss: 1.2066 - dyskinesia_loss: 0.4905 - tremor_loss: 0.5485\n",
      "Epoch 00011: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 2.2454 - on_off_loss: 1.2066 - dyskinesia_loss: 0.4905 - tremor_loss: 0.5483 - val_loss: 3.5213 - val_on_off_loss: 1.8740 - val_dyskinesia_loss: 0.8407 - val_tremor_loss: 0.8066\n",
      "Epoch 12/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1012 - on_off_loss: 1.1230 - dyskinesia_loss: 0.4627 - tremor_loss: 0.5155\n",
      "Epoch 00012: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 2.1012 - on_off_loss: 1.1232 - dyskinesia_loss: 0.4625 - tremor_loss: 0.5155 - val_loss: 3.4649 - val_on_off_loss: 1.7577 - val_dyskinesia_loss: 0.8684 - val_tremor_loss: 0.8388\n",
      "Epoch 13/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.9778 - on_off_loss: 1.0494 - dyskinesia_loss: 0.4389 - tremor_loss: 0.4894\n",
      "Epoch 00013: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.9779 - on_off_loss: 1.0497 - dyskinesia_loss: 0.4388 - tremor_loss: 0.4894 - val_loss: 3.7809 - val_on_off_loss: 2.0368 - val_dyskinesia_loss: 0.8709 - val_tremor_loss: 0.8732\n",
      "Epoch 14/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.8588 - on_off_loss: 0.9834 - dyskinesia_loss: 0.4132 - tremor_loss: 0.4622\n",
      "Epoch 00014: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.8593 - on_off_loss: 0.9835 - dyskinesia_loss: 0.4135 - tremor_loss: 0.4623 - val_loss: 3.4481 - val_on_off_loss: 1.7913 - val_dyskinesia_loss: 0.8451 - val_tremor_loss: 0.8116\n",
      "Epoch 15/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.7223 - on_off_loss: 0.9032 - dyskinesia_loss: 0.3856 - tremor_loss: 0.4335\n",
      "Epoch 00015: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.7218 - on_off_loss: 0.9029 - dyskinesia_loss: 0.3856 - tremor_loss: 0.4333 - val_loss: 3.6611 - val_on_off_loss: 1.9183 - val_dyskinesia_loss: 0.8592 - val_tremor_loss: 0.8836\n",
      "Epoch 16/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.6241 - on_off_loss: 0.8430 - dyskinesia_loss: 0.3678 - tremor_loss: 0.4132\n",
      "Epoch 00016: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.6239 - on_off_loss: 0.8430 - dyskinesia_loss: 0.3677 - tremor_loss: 0.4131 - val_loss: 3.7704 - val_on_off_loss: 1.9366 - val_dyskinesia_loss: 0.9223 - val_tremor_loss: 0.9115\n",
      "Epoch 17/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4915 - on_off_loss: 0.7639 - dyskinesia_loss: 0.3407 - tremor_loss: 0.3870\n",
      "Epoch 00017: val_loss did not improve from 3.27607\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 1.4922 - on_off_loss: 0.7643 - dyskinesia_loss: 0.3408 - tremor_loss: 0.3871 - val_loss: 3.9230 - val_on_off_loss: 2.1628 - val_dyskinesia_loss: 0.8851 - val_tremor_loss: 0.8751\n",
      "Epoch 18/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2651 - on_off_loss: 0.6358 - dyskinesia_loss: 0.2928 - tremor_loss: 0.3365\n",
      "Epoch 00018: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.2650 - on_off_loss: 0.6358 - dyskinesia_loss: 0.2928 - tremor_loss: 0.3364 - val_loss: 3.7665 - val_on_off_loss: 1.9865 - val_dyskinesia_loss: 0.9138 - val_tremor_loss: 0.8663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1608 - on_off_loss: 0.5737 - dyskinesia_loss: 0.2729 - tremor_loss: 0.3142\n",
      "Epoch 00019: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.1613 - on_off_loss: 0.5738 - dyskinesia_loss: 0.2732 - tremor_loss: 0.3143 - val_loss: 3.8339 - val_on_off_loss: 2.0338 - val_dyskinesia_loss: 0.9199 - val_tremor_loss: 0.8802\n",
      "Epoch 20/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1214 - on_off_loss: 0.5477 - dyskinesia_loss: 0.2666 - tremor_loss: 0.3071\n",
      "Epoch 00020: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.1210 - on_off_loss: 0.5476 - dyskinesia_loss: 0.2665 - tremor_loss: 0.3069 - val_loss: 3.9257 - val_on_off_loss: 2.1199 - val_dyskinesia_loss: 0.9266 - val_tremor_loss: 0.8793\n",
      "Epoch 21/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0771 - on_off_loss: 0.5234 - dyskinesia_loss: 0.2561 - tremor_loss: 0.2977\n",
      "Epoch 00021: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.0768 - on_off_loss: 0.5233 - dyskinesia_loss: 0.2560 - tremor_loss: 0.2976 - val_loss: 3.8789 - val_on_off_loss: 2.0522 - val_dyskinesia_loss: 0.9370 - val_tremor_loss: 0.8897\n",
      "Epoch 22/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0458 - on_off_loss: 0.5070 - dyskinesia_loss: 0.2484 - tremor_loss: 0.2904\n",
      "Epoch 00022: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.0454 - on_off_loss: 0.5065 - dyskinesia_loss: 0.2484 - tremor_loss: 0.2905 - val_loss: 3.9000 - val_on_off_loss: 2.0697 - val_dyskinesia_loss: 0.9317 - val_tremor_loss: 0.8987\n",
      "Epoch 23/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0237 - on_off_loss: 0.4949 - dyskinesia_loss: 0.2445 - tremor_loss: 0.2843\n",
      "Epoch 00023: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.0237 - on_off_loss: 0.4948 - dyskinesia_loss: 0.2446 - tremor_loss: 0.2843 - val_loss: 3.8711 - val_on_off_loss: 2.0399 - val_dyskinesia_loss: 0.9478 - val_tremor_loss: 0.8834\n",
      "Epoch 24/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9980 - on_off_loss: 0.4797 - dyskinesia_loss: 0.2383 - tremor_loss: 0.2801\n",
      "Epoch 00024: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.9981 - on_off_loss: 0.4798 - dyskinesia_loss: 0.2382 - tremor_loss: 0.2801 - val_loss: 3.8915 - val_on_off_loss: 2.0506 - val_dyskinesia_loss: 0.9544 - val_tremor_loss: 0.8865\n",
      "Epoch 25/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9684 - on_off_loss: 0.4575 - dyskinesia_loss: 0.2358 - tremor_loss: 0.2752\n",
      "Epoch 00025: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.9684 - on_off_loss: 0.4572 - dyskinesia_loss: 0.2358 - tremor_loss: 0.2753 - val_loss: 4.0004 - val_on_off_loss: 2.1441 - val_dyskinesia_loss: 0.9502 - val_tremor_loss: 0.9061\n",
      "Epoch 26/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9510 - on_off_loss: 0.4510 - dyskinesia_loss: 0.2297 - tremor_loss: 0.2703\n",
      "Epoch 00026: val_loss did not improve from 3.27607\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.9509 - on_off_loss: 0.4511 - dyskinesia_loss: 0.2296 - tremor_loss: 0.2702 - val_loss: 3.9615 - val_on_off_loss: 2.1162 - val_dyskinesia_loss: 0.9478 - val_tremor_loss: 0.8975\n",
      "Epoch 27/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9163 - on_off_loss: 0.4303 - dyskinesia_loss: 0.2211 - tremor_loss: 0.2649\n",
      "Epoch 00027: val_loss did not improve from 3.27607\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.9163 - on_off_loss: 0.4303 - dyskinesia_loss: 0.2211 - tremor_loss: 0.2649 - val_loss: 4.0416 - val_on_off_loss: 2.1429 - val_dyskinesia_loss: 0.9691 - val_tremor_loss: 0.9296\n"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm2.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'on_off_loss', 'dyskinesia_loss', 'tremor_loss', 'val_loss', 'val_on_off_loss', 'val_dyskinesia_loss', 'val_tremor_loss', 'lr'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = Dict(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbeebb7b9b0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.on_off_loss)\n",
    "plt.plot(history.val_on_off_loss)\n",
    "plt.legend([\"Train On Off\", \"Valid On Off\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbeebb65898>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.dyskinesia_loss)\n",
    "plt.plot(history.val_dyskinesia_loss)\n",
    "plt.legend([\"Train Dyskinesia\", \"Valid Dyskinesia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbeebad4f98>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.tremor_loss)\n",
    "plt.plot(history.val_tremor_loss)\n",
    "plt.legend([\"Train Tremor\", \"Valid Tremor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More parameters and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_batched_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c900c02ade1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_batched_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=512)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 0\n",
    "num_lin_layers = 3\n",
    "dropout = 0.5\n",
    "lin_h=512\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.05)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(16, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.CuDNNLSTM(256, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(200)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off, x_dyskinesia, x_tremor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_85 (InputLayer)           (None, 1500, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 1500, 3)      0           input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_314 (Bat (None, 1500, 3)      12          gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 1500, 16)     160         batch_normalization_v1_314[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_343 (LeakyReLU)     (None, 1500, 16)     0           conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_145 (MaxPooling1D (None, 750, 16)      0           leaky_re_lu_343[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_315 (Bat (None, 750, 16)      64          max_pooling1d_145[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 750, 16)      784         batch_normalization_v1_315[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_344 (LeakyReLU)     (None, 750, 16)      0           conv1d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_146 (MaxPooling1D (None, 375, 16)      0           leaky_re_lu_344[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_316 (Bat (None, 375, 16)      64          max_pooling1d_146[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 375, 16)      784         batch_normalization_v1_316[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_345 (LeakyReLU)     (None, 375, 16)      0           conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_147 (MaxPooling1D (None, 187, 16)      0           leaky_re_lu_345[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_317 (Bat (None, 187, 16)      64          max_pooling1d_147[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 187, 16)      784         batch_normalization_v1_317[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_346 (LeakyReLU)     (None, 187, 16)      0           conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_148 (MaxPooling1D (None, 93, 16)       0           leaky_re_lu_346[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_318 (Bat (None, 93, 16)       64          max_pooling1d_148[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 93, 16)       784         batch_normalization_v1_318[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_347 (LeakyReLU)     (None, 93, 16)       0           conv1d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_149 (MaxPooling1D (None, 46, 16)       0           leaky_re_lu_347[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_encoder_lstm (Flatten)  (None, 736)          0           max_pooling1d_149[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_249 (Dense)               (None, 200)          147400      flatten_encoder_lstm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_348 (LeakyReLU)     (None, 200)          0           dense_249[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 200)          0           leaky_re_lu_348[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_319 (Bat (None, 200)          800         dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_322 (Bat (None, 200)          800         dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_325 (Bat (None, 200)          800         dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_250 (Dense)               (None, 512)          102912      batch_normalization_v1_319[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 512)          102912      batch_normalization_v1_322[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 512)          102912      batch_normalization_v1_325[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_349 (LeakyReLU)     (None, 512)          0           dense_250[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_352 (LeakyReLU)     (None, 512)          0           dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_355 (LeakyReLU)     (None, 512)          0           dense_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 512)          0           leaky_re_lu_349[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 512)          0           leaky_re_lu_352[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)           (None, 512)          0           leaky_re_lu_355[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_320 (Bat (None, 512)          2048        dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_323 (Bat (None, 512)          2048        dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_326 (Bat (None, 512)          2048        dropout_181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_251 (Dense)               (None, 512)          262656      batch_normalization_v1_320[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 512)          262656      batch_normalization_v1_323[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_259 (Dense)               (None, 512)          262656      batch_normalization_v1_326[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_350 (LeakyReLU)     (None, 512)          0           dense_251[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_353 (LeakyReLU)     (None, 512)          0           dense_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_356 (LeakyReLU)     (None, 512)          0           dense_259[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 512)          0           leaky_re_lu_350[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 512)          0           leaky_re_lu_353[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)           (None, 512)          0           leaky_re_lu_356[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_321 (Bat (None, 512)          2048        dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_324 (Bat (None, 512)          2048        dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_327 (Bat (None, 512)          2048        dropout_182[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_252 (Dense)               (None, 512)          262656      batch_normalization_v1_321[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 512)          262656      batch_normalization_v1_324[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_260 (Dense)               (None, 512)          262656      batch_normalization_v1_327[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_351 (LeakyReLU)     (None, 512)          0           dense_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_354 (LeakyReLU)     (None, 512)          0           dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_357 (LeakyReLU)     (None, 512)          0           dense_260[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 512)          0           leaky_re_lu_351[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)           (None, 512)          0           leaky_re_lu_354[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)           (None, 512)          0           leaky_re_lu_357[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 1)            513         dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 1)            513         dropout_180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_261 (Dense)               (None, 1)            513         dropout_183[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 1)            0           dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 1)            0           dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 1)            0           dense_261[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,051,863\n",
      "Trainable params: 2,044,385\n",
      "Non-trainable params: 7,478\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=[\"mean_squared_error\", \"mean_squared_error\", \"mean_squared_error\", ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.8427 - on_off_loss: 2.3068 - dyskinesia_loss: 1.1412 - tremor_loss: 1.3947\n",
      "Epoch 00001: val_loss improved from inf to 5.04465, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 116s 231ms/step - loss: 4.8431 - on_off_loss: 2.3071 - dyskinesia_loss: 1.1412 - tremor_loss: 1.3948 - val_loss: 5.0446 - val_on_off_loss: 2.3104 - val_dyskinesia_loss: 1.1992 - val_tremor_loss: 1.5350\n",
      "Epoch 2/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 4.8880 - on_off_loss: 2.3345 - dyskinesia_loss: 1.1494 - tremor_loss: 1.4042\n",
      "Epoch 00002: val_loss improved from 5.04465 to 5.01986, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 43s 87ms/step - loss: 4.8882 - on_off_loss: 2.3348 - dyskinesia_loss: 1.1494 - tremor_loss: 1.4040 - val_loss: 5.0199 - val_on_off_loss: 2.3011 - val_dyskinesia_loss: 1.1922 - val_tremor_loss: 1.5265\n",
      "Epoch 3/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 4.8720 - on_off_loss: 2.3419 - dyskinesia_loss: 1.1334 - tremor_loss: 1.3967\n",
      "Epoch 00003: val_loss did not improve from 5.01986\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 4.8715 - on_off_loss: 2.3423 - dyskinesia_loss: 1.1329 - tremor_loss: 1.3962 - val_loss: 5.0543 - val_on_off_loss: 2.3151 - val_dyskinesia_loss: 1.2016 - val_tremor_loss: 1.5376\n",
      "Epoch 4/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 4.8371 - on_off_loss: 2.3078 - dyskinesia_loss: 1.1391 - tremor_loss: 1.3902\n",
      "Epoch 00004: val_loss did not improve from 5.01986\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 4.8400 - on_off_loss: 2.3085 - dyskinesia_loss: 1.1400 - tremor_loss: 1.3915 - val_loss: 5.0228 - val_on_off_loss: 2.2984 - val_dyskinesia_loss: 1.1929 - val_tremor_loss: 1.5315\n",
      "Epoch 5/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.8925 - on_off_loss: 2.3371 - dyskinesia_loss: 1.1490 - tremor_loss: 1.4064\n",
      "Epoch 00005: val_loss did not improve from 5.01986\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 4.8907 - on_off_loss: 2.3360 - dyskinesia_loss: 1.1487 - tremor_loss: 1.4060 - val_loss: 5.0386 - val_on_off_loss: 2.3114 - val_dyskinesia_loss: 1.1927 - val_tremor_loss: 1.5345\n",
      "Epoch 6/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 4.8627 - on_off_loss: 2.3322 - dyskinesia_loss: 1.1348 - tremor_loss: 1.3957\n",
      "Epoch 00006: val_loss did not improve from 5.01986\n",
      "500/500 [==============================] - 43s 86ms/step - loss: 4.8626 - on_off_loss: 2.3318 - dyskinesia_loss: 1.1350 - tremor_loss: 1.3958 - val_loss: 5.0391 - val_on_off_loss: 2.3035 - val_dyskinesia_loss: 1.2011 - val_tremor_loss: 1.5345\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.8465 - on_off_loss: 2.3127 - dyskinesia_loss: 1.1410 - tremor_loss: 1.3928\n",
      "Epoch 00007: val_loss improved from 5.01986 to 5.01436, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 4.8470 - on_off_loss: 2.3127 - dyskinesia_loss: 1.1412 - tremor_loss: 1.3930 - val_loss: 5.0144 - val_on_off_loss: 2.3005 - val_dyskinesia_loss: 1.1878 - val_tremor_loss: 1.5261\n",
      "Epoch 8/200\n",
      "498/500 [============================>.] - ETA: 0s - loss: 4.8877 - on_off_loss: 2.3345 - dyskinesia_loss: 1.1491 - tremor_loss: 1.4041\n",
      "Epoch 00008: val_loss did not improve from 5.01436\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 4.8890 - on_off_loss: 2.3352 - dyskinesia_loss: 1.1494 - tremor_loss: 1.4044 - val_loss: 5.0484 - val_on_off_loss: 2.3129 - val_dyskinesia_loss: 1.2011 - val_tremor_loss: 1.5345\n",
      "Epoch 9/200\n",
      "438/500 [=========================>....] - ETA: 2s - loss: 4.8605 - on_off_loss: 2.3230 - dyskinesia_loss: 1.1371 - tremor_loss: 1.4004"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm2.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation with Rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally believed that watches can be rotated somewhat. We don't remove the gravity component still, so the network should be able to figure out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/matthew-brett/transforms3d/blob/master/transforms3d/axangles.py\n",
    "def tfaxangle2mat(x, y, z, angle, is_normalized=False):\n",
    "#     x, y, z = axis\n",
    "    if not is_normalized:\n",
    "        n = tf.math.sqrt(x*x + y*y + z*z)\n",
    "        x = x/n\n",
    "        y = y/n\n",
    "        z = z/n\n",
    "    c = tf.math.cos(angle); s = tf.math.sin(angle); C = 1-c\n",
    "    xs = x*s;   ys = y*s;   zs = z*s\n",
    "    xC = x*C;   yC = y*C;   zC = z*C\n",
    "    xyC = x*yC; yzC = y*zC; zxC = z*xC\n",
    "    return tf.reshape(tf.concat([\n",
    "             x*xC+c,   xyC-zs,   zxC+ys ,\n",
    "             xyC+zs,   y*yC+c,   yzC-xs ,\n",
    "             zxC-ys,   yzC+xs,   z*zC+c ], axis=-1), (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfaxangle2mat(tf.constant(0.0), tf.constant(0.0), tf.constant(1.0), tf.random.normal((1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 1/16 #allow deviation from real rotation with pi/16 std\n",
    "def map_example_to_simple_train(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    update_matrix = tfaxangle2mat(tf.constant(0.0), tf.constant(0.0), tf.constant(1.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(0.0), tf.constant(1.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(1.0), tf.constant(0.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    data = data @ update_matrix\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c900c02ade1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4e8fbf3f8071>\u001b[0m in \u001b[0;36mget_batched_dataset\u001b[0;34m(filenames, batch_size, m_ids, max_queue_size, n_process, map_example)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         dataset = dataset.map(map_example_to_simple_train, num_parallel_calls=n_process)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     dataset = dataset.filter(lambda x, y: tf.math.reduce_std(x) > 0.05)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1582\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1583\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1584\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m     super(ParallelMapDataset, self).__init__(\n\u001b[0;32m-> 2771\u001b[0;31m         input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2735\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2737\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, defun_kwargs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m     self._func_name = \"_\".join([\n\u001b[1;32m   2081\u001b[0m         \u001b[0mreadable_transformation_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m         \u001b[0mfunction_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_func_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m     ])\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/util/function_utils.py\u001b[0m in \u001b[0;36mget_func_name\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     95\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Argument must be callable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be callable"
     ]
    }
   ],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128, map_example=map_example_to_simple_train)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=512)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-708e2f5502b8>:2: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204098"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for record in tf.python_io.tf_record_iterator(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\"):\n",
    "    c += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 0\n",
    "num_lin_layers = 5\n",
    "dropout = 0.5\n",
    "lin_h=512\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(16, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(256, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(lin_h)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off, x_dyskinesia, x_tremor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1500, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 1500, 3)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1500, 16)     160         gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 1500, 16)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 750, 16)      0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 750, 16)      64          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 750, 16)      784         batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 750, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 375, 16)      0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 375, 16)      64          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 375, 16)      784         batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 375, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 187, 16)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 187, 16)      64          max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 187, 16)      784         batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 187, 16)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 93, 16)       0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 93, 16)       64          max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 93, 16)       784         batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 93, 16)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 46, 16)       0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 46, 16)       64          max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_encoder_lstm (Flatten)  (None, 736)          0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          377344      flatten_encoder_lstm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          262656      batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 512)          262656      batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 512)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 512)          2048        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 512)          2048        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          262656      batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 512)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 512)          2048        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 512)          2048        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 512)          2048        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          262656      batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 512)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512)          0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 512)          2048        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 512)          2048        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 512)          2048        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          262656      batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          262656      batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 512)          262656      batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 512)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 512)          0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 512)          2048        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 512)          2048        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 512)          2048        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          262656      batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          262656      batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 512)          262656      batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 512)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 512)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512)          0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            513         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            513         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            513         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 1)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 1)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 1)            0           dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,353,059\n",
      "Trainable params: 4,337,539\n",
      "Non-trainable params: 15,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(lr=0.001), loss=[\"mean_squared_error\", \"mean_squared_error\", \"mean_squared_error\", ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.6631 - on_off_loss: 2.2437 - dyskinesia_loss: 1.2006 - tremor_loss: 1.2188\n",
      "Epoch 00001: val_loss improved from inf to 3.43121, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 105s 209ms/step - loss: 4.6611 - on_off_loss: 2.2433 - dyskinesia_loss: 1.1997 - tremor_loss: 1.2181 - val_loss: 3.4312 - val_on_off_loss: 1.6491 - val_dyskinesia_loss: 0.8299 - val_tremor_loss: 0.9522\n",
      "Epoch 2/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.8887 - on_off_loss: 1.9107 - dyskinesia_loss: 1.0052 - tremor_loss: 0.9727\n",
      "Epoch 00002: val_loss improved from 3.43121 to 3.35283, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 3.8892 - on_off_loss: 1.9108 - dyskinesia_loss: 1.0056 - tremor_loss: 0.9729 - val_loss: 3.3528 - val_on_off_loss: 1.6161 - val_dyskinesia_loss: 0.8040 - val_tremor_loss: 0.9327\n",
      "Epoch 3/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7944 - on_off_loss: 1.8680 - dyskinesia_loss: 0.9865 - tremor_loss: 0.9399\n",
      "Epoch 00003: val_loss improved from 3.35283 to 3.34129, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 3.7945 - on_off_loss: 1.8681 - dyskinesia_loss: 0.9864 - tremor_loss: 0.9401 - val_loss: 3.3413 - val_on_off_loss: 1.6014 - val_dyskinesia_loss: 0.7999 - val_tremor_loss: 0.9400\n",
      "Epoch 4/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7692 - on_off_loss: 1.8596 - dyskinesia_loss: 0.9800 - tremor_loss: 0.9296\n",
      "Epoch 00004: val_loss improved from 3.34129 to 3.33480, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.7695 - on_off_loss: 1.8597 - dyskinesia_loss: 0.9797 - tremor_loss: 0.9300 - val_loss: 3.3348 - val_on_off_loss: 1.6249 - val_dyskinesia_loss: 0.8024 - val_tremor_loss: 0.9075\n",
      "Epoch 5/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7419 - on_off_loss: 1.8404 - dyskinesia_loss: 0.9800 - tremor_loss: 0.9216\n",
      "Epoch 00005: val_loss improved from 3.33480 to 3.26492, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.7421 - on_off_loss: 1.8402 - dyskinesia_loss: 0.9802 - tremor_loss: 0.9217 - val_loss: 3.2649 - val_on_off_loss: 1.5860 - val_dyskinesia_loss: 0.7878 - val_tremor_loss: 0.8911\n",
      "Epoch 6/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7419 - on_off_loss: 1.8452 - dyskinesia_loss: 0.9776 - tremor_loss: 0.9191\n",
      "Epoch 00006: val_loss did not improve from 3.26492\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 3.7425 - on_off_loss: 1.8458 - dyskinesia_loss: 0.9775 - tremor_loss: 0.9191 - val_loss: 3.3598 - val_on_off_loss: 1.6388 - val_dyskinesia_loss: 0.8017 - val_tremor_loss: 0.9194\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.7295 - on_off_loss: 1.8338 - dyskinesia_loss: 0.9827 - tremor_loss: 0.9130\n",
      "Epoch 00007: val_loss improved from 3.26492 to 3.24665, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 3.7292 - on_off_loss: 1.8336 - dyskinesia_loss: 0.9826 - tremor_loss: 0.9130 - val_loss: 3.2467 - val_on_off_loss: 1.5779 - val_dyskinesia_loss: 0.8033 - val_tremor_loss: 0.8655\n",
      "Epoch 8/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.6861 - on_off_loss: 1.8187 - dyskinesia_loss: 0.9672 - tremor_loss: 0.9002\n",
      "Epoch 00008: val_loss improved from 3.24665 to 3.23627, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 181ms/step - loss: 3.6867 - on_off_loss: 1.8185 - dyskinesia_loss: 0.9677 - tremor_loss: 0.9005 - val_loss: 3.2363 - val_on_off_loss: 1.5968 - val_dyskinesia_loss: 0.7667 - val_tremor_loss: 0.8728\n",
      "Epoch 9/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.6639 - on_off_loss: 1.8139 - dyskinesia_loss: 0.9589 - tremor_loss: 0.8911\n",
      "Epoch 00009: val_loss improved from 3.23627 to 3.17196, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.6630 - on_off_loss: 1.8134 - dyskinesia_loss: 0.9588 - tremor_loss: 0.8908 - val_loss: 3.1720 - val_on_off_loss: 1.5725 - val_dyskinesia_loss: 0.7579 - val_tremor_loss: 0.8416\n",
      "Epoch 10/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.6427 - on_off_loss: 1.8064 - dyskinesia_loss: 0.9516 - tremor_loss: 0.8847\n",
      "Epoch 00010: val_loss did not improve from 3.17196\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.6424 - on_off_loss: 1.8063 - dyskinesia_loss: 0.9515 - tremor_loss: 0.8846 - val_loss: 3.1798 - val_on_off_loss: 1.5799 - val_dyskinesia_loss: 0.7470 - val_tremor_loss: 0.8529\n",
      "Epoch 11/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.6139 - on_off_loss: 1.7995 - dyskinesia_loss: 0.9369 - tremor_loss: 0.8774\n",
      "Epoch 00011: val_loss did not improve from 3.17196\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.6136 - on_off_loss: 1.7991 - dyskinesia_loss: 0.9369 - tremor_loss: 0.8775 - val_loss: 3.2533 - val_on_off_loss: 1.6468 - val_dyskinesia_loss: 0.7607 - val_tremor_loss: 0.8458\n",
      "Epoch 12/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.6053 - on_off_loss: 1.7994 - dyskinesia_loss: 0.9347 - tremor_loss: 0.8712\n",
      "Epoch 00012: val_loss did not improve from 3.17196\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.6050 - on_off_loss: 1.7989 - dyskinesia_loss: 0.9348 - tremor_loss: 0.8713 - val_loss: 3.2049 - val_on_off_loss: 1.6077 - val_dyskinesia_loss: 0.7537 - val_tremor_loss: 0.8435\n",
      "Epoch 13/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.5742 - on_off_loss: 1.7886 - dyskinesia_loss: 0.9209 - tremor_loss: 0.8646\n",
      "Epoch 00013: val_loss did not improve from 3.17196\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.5748 - on_off_loss: 1.7888 - dyskinesia_loss: 0.9212 - tremor_loss: 0.8649 - val_loss: 3.2044 - val_on_off_loss: 1.5974 - val_dyskinesia_loss: 0.7640 - val_tremor_loss: 0.8429\n",
      "Epoch 14/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.5617 - on_off_loss: 1.7917 - dyskinesia_loss: 0.9127 - tremor_loss: 0.8573\n",
      "Epoch 00014: val_loss did not improve from 3.17196\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.5617 - on_off_loss: 1.7919 - dyskinesia_loss: 0.9125 - tremor_loss: 0.8573 - val_loss: 3.2531 - val_on_off_loss: 1.6188 - val_dyskinesia_loss: 0.7781 - val_tremor_loss: 0.8562\n",
      "Epoch 15/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.5116 - on_off_loss: 1.7744 - dyskinesia_loss: 0.8982 - tremor_loss: 0.8390\n",
      "Epoch 00015: val_loss improved from 3.17196 to 3.16681, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.5116 - on_off_loss: 1.7742 - dyskinesia_loss: 0.8984 - tremor_loss: 0.8389 - val_loss: 3.1668 - val_on_off_loss: 1.5983 - val_dyskinesia_loss: 0.7364 - val_tremor_loss: 0.8321\n",
      "Epoch 16/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4831 - on_off_loss: 1.7696 - dyskinesia_loss: 0.8857 - tremor_loss: 0.8279\n",
      "Epoch 00016: val_loss did not improve from 3.16681\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 3.4830 - on_off_loss: 1.7693 - dyskinesia_loss: 0.8856 - tremor_loss: 0.8280 - val_loss: 3.1722 - val_on_off_loss: 1.6016 - val_dyskinesia_loss: 0.7343 - val_tremor_loss: 0.8362\n",
      "Epoch 17/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4613 - on_off_loss: 1.7596 - dyskinesia_loss: 0.8813 - tremor_loss: 0.8204\n",
      "Epoch 00017: val_loss improved from 3.16681 to 3.16441, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.4611 - on_off_loss: 1.7596 - dyskinesia_loss: 0.8811 - tremor_loss: 0.8203 - val_loss: 3.1644 - val_on_off_loss: 1.5954 - val_dyskinesia_loss: 0.7421 - val_tremor_loss: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4657 - on_off_loss: 1.7608 - dyskinesia_loss: 0.8820 - tremor_loss: 0.8229\n",
      "Epoch 00018: val_loss improved from 3.16441 to 3.15552, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.4655 - on_off_loss: 1.7604 - dyskinesia_loss: 0.8822 - tremor_loss: 0.8229 - val_loss: 3.1555 - val_on_off_loss: 1.5921 - val_dyskinesia_loss: 0.7373 - val_tremor_loss: 0.8261\n",
      "Epoch 19/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4541 - on_off_loss: 1.7576 - dyskinesia_loss: 0.8772 - tremor_loss: 0.8192\n",
      "Epoch 00019: val_loss improved from 3.15552 to 3.15048, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.4539 - on_off_loss: 1.7575 - dyskinesia_loss: 0.8772 - tremor_loss: 0.8192 - val_loss: 3.1505 - val_on_off_loss: 1.5892 - val_dyskinesia_loss: 0.7365 - val_tremor_loss: 0.8248\n",
      "Epoch 20/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4498 - on_off_loss: 1.7542 - dyskinesia_loss: 0.8753 - tremor_loss: 0.8203\n",
      "Epoch 00020: val_loss did not improve from 3.15048\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.4498 - on_off_loss: 1.7545 - dyskinesia_loss: 0.8750 - tremor_loss: 0.8203 - val_loss: 3.1515 - val_on_off_loss: 1.5986 - val_dyskinesia_loss: 0.7292 - val_tremor_loss: 0.8237\n",
      "Epoch 21/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4348 - on_off_loss: 1.7531 - dyskinesia_loss: 0.8699 - tremor_loss: 0.8118\n",
      "Epoch 00021: val_loss did not improve from 3.15048\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.4344 - on_off_loss: 1.7529 - dyskinesia_loss: 0.8697 - tremor_loss: 0.8118 - val_loss: 3.1555 - val_on_off_loss: 1.5926 - val_dyskinesia_loss: 0.7374 - val_tremor_loss: 0.8254\n",
      "Epoch 22/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4348 - on_off_loss: 1.7489 - dyskinesia_loss: 0.8730 - tremor_loss: 0.8128\n",
      "Epoch 00022: val_loss did not improve from 3.15048\n",
      "500/500 [==============================] - 90s 181ms/step - loss: 3.4351 - on_off_loss: 1.7487 - dyskinesia_loss: 0.8733 - tremor_loss: 0.8130 - val_loss: 3.1557 - val_on_off_loss: 1.5948 - val_dyskinesia_loss: 0.7374 - val_tremor_loss: 0.8234\n",
      "Epoch 23/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4246 - on_off_loss: 1.7453 - dyskinesia_loss: 0.8672 - tremor_loss: 0.8120\n",
      "Epoch 00023: val_loss did not improve from 3.15048\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.4246 - on_off_loss: 1.7453 - dyskinesia_loss: 0.8675 - tremor_loss: 0.8118 - val_loss: 3.1567 - val_on_off_loss: 1.5943 - val_dyskinesia_loss: 0.7434 - val_tremor_loss: 0.8191\n",
      "Epoch 24/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4078 - on_off_loss: 1.7398 - dyskinesia_loss: 0.8612 - tremor_loss: 0.8068\n",
      "Epoch 00024: val_loss improved from 3.15048 to 3.12954, saving model to /n/scratch2/ms994/cnnlstm2.h5\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 3.4079 - on_off_loss: 1.7401 - dyskinesia_loss: 0.8612 - tremor_loss: 0.8066 - val_loss: 3.1295 - val_on_off_loss: 1.5831 - val_dyskinesia_loss: 0.7337 - val_tremor_loss: 0.8128\n",
      "Epoch 25/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4147 - on_off_loss: 1.7420 - dyskinesia_loss: 0.8626 - tremor_loss: 0.8101\n",
      "Epoch 00025: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.4147 - on_off_loss: 1.7422 - dyskinesia_loss: 0.8626 - tremor_loss: 0.8100 - val_loss: 3.1420 - val_on_off_loss: 1.5965 - val_dyskinesia_loss: 0.7294 - val_tremor_loss: 0.8160\n",
      "Epoch 26/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.4000 - on_off_loss: 1.7401 - dyskinesia_loss: 0.8554 - tremor_loss: 0.8046\n",
      "Epoch 00026: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.4006 - on_off_loss: 1.7400 - dyskinesia_loss: 0.8556 - tremor_loss: 0.8050 - val_loss: 3.1445 - val_on_off_loss: 1.5942 - val_dyskinesia_loss: 0.7324 - val_tremor_loss: 0.8179\n",
      "Epoch 27/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3973 - on_off_loss: 1.7389 - dyskinesia_loss: 0.8566 - tremor_loss: 0.8017\n",
      "Epoch 00027: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.3976 - on_off_loss: 1.7392 - dyskinesia_loss: 0.8567 - tremor_loss: 0.8017 - val_loss: 3.1650 - val_on_off_loss: 1.6030 - val_dyskinesia_loss: 0.7411 - val_tremor_loss: 0.8210\n",
      "Epoch 28/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3890 - on_off_loss: 1.7354 - dyskinesia_loss: 0.8543 - tremor_loss: 0.7994\n",
      "Epoch 00028: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.3889 - on_off_loss: 1.7352 - dyskinesia_loss: 0.8542 - tremor_loss: 0.7994 - val_loss: 3.1470 - val_on_off_loss: 1.5836 - val_dyskinesia_loss: 0.7449 - val_tremor_loss: 0.8185\n",
      "Epoch 29/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3924 - on_off_loss: 1.7348 - dyskinesia_loss: 0.8554 - tremor_loss: 0.8021\n",
      "Epoch 00029: val_loss did not improve from 3.12954\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.3926 - on_off_loss: 1.7346 - dyskinesia_loss: 0.8557 - tremor_loss: 0.8023 - val_loss: 3.1353 - val_on_off_loss: 1.5838 - val_dyskinesia_loss: 0.7393 - val_tremor_loss: 0.8122\n",
      "Epoch 30/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3699 - on_off_loss: 1.7300 - dyskinesia_loss: 0.8457 - tremor_loss: 0.7943\n",
      "Epoch 00030: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 3.3702 - on_off_loss: 1.7302 - dyskinesia_loss: 0.8456 - tremor_loss: 0.7944 - val_loss: 3.1427 - val_on_off_loss: 1.5961 - val_dyskinesia_loss: 0.7355 - val_tremor_loss: 0.8111\n",
      "Epoch 31/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3775 - on_off_loss: 1.7310 - dyskinesia_loss: 0.8493 - tremor_loss: 0.7972\n",
      "Epoch 00031: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.3771 - on_off_loss: 1.7308 - dyskinesia_loss: 0.8491 - tremor_loss: 0.7972 - val_loss: 3.1373 - val_on_off_loss: 1.5936 - val_dyskinesia_loss: 0.7337 - val_tremor_loss: 0.8099\n",
      "Epoch 32/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3709 - on_off_loss: 1.7308 - dyskinesia_loss: 0.8454 - tremor_loss: 0.7947\n",
      "Epoch 00032: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3711 - on_off_loss: 1.7305 - dyskinesia_loss: 0.8458 - tremor_loss: 0.7949 - val_loss: 3.1327 - val_on_off_loss: 1.5907 - val_dyskinesia_loss: 0.7325 - val_tremor_loss: 0.8095\n",
      "Epoch 33/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3692 - on_off_loss: 1.7313 - dyskinesia_loss: 0.8459 - tremor_loss: 0.7920\n",
      "Epoch 00033: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3690 - on_off_loss: 1.7312 - dyskinesia_loss: 0.8458 - tremor_loss: 0.7920 - val_loss: 3.1449 - val_on_off_loss: 1.6011 - val_dyskinesia_loss: 0.7329 - val_tremor_loss: 0.8108\n",
      "Epoch 34/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3741 - on_off_loss: 1.7268 - dyskinesia_loss: 0.8501 - tremor_loss: 0.7972\n",
      "Epoch 00034: val_loss did not improve from 3.12954\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3751 - on_off_loss: 1.7270 - dyskinesia_loss: 0.8503 - tremor_loss: 0.7978 - val_loss: 3.1358 - val_on_off_loss: 1.5931 - val_dyskinesia_loss: 0.7349 - val_tremor_loss: 0.8078\n",
      "Epoch 35/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3668 - on_off_loss: 1.7275 - dyskinesia_loss: 0.8455 - tremor_loss: 0.7938\n",
      "Epoch 00035: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 3.3661 - on_off_loss: 1.7274 - dyskinesia_loss: 0.8451 - tremor_loss: 0.7935 - val_loss: 3.1395 - val_on_off_loss: 1.5963 - val_dyskinesia_loss: 0.7337 - val_tremor_loss: 0.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3808 - on_off_loss: 1.7327 - dyskinesia_loss: 0.8490 - tremor_loss: 0.7991\n",
      "Epoch 00036: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3799 - on_off_loss: 1.7324 - dyskinesia_loss: 0.8487 - tremor_loss: 0.7988 - val_loss: 3.1408 - val_on_off_loss: 1.5969 - val_dyskinesia_loss: 0.7307 - val_tremor_loss: 0.8132\n",
      "Epoch 37/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3664 - on_off_loss: 1.7290 - dyskinesia_loss: 0.8436 - tremor_loss: 0.7937\n",
      "Epoch 00037: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3655 - on_off_loss: 1.7288 - dyskinesia_loss: 0.8434 - tremor_loss: 0.7933 - val_loss: 3.1410 - val_on_off_loss: 1.5956 - val_dyskinesia_loss: 0.7331 - val_tremor_loss: 0.8123\n",
      "Epoch 38/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3730 - on_off_loss: 1.7329 - dyskinesia_loss: 0.8448 - tremor_loss: 0.7953\n",
      "Epoch 00038: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 3.3733 - on_off_loss: 1.7323 - dyskinesia_loss: 0.8453 - tremor_loss: 0.7957 - val_loss: 3.1391 - val_on_off_loss: 1.5946 - val_dyskinesia_loss: 0.7322 - val_tremor_loss: 0.8123\n",
      "Epoch 39/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3768 - on_off_loss: 1.7303 - dyskinesia_loss: 0.8513 - tremor_loss: 0.7952\n",
      "Epoch 00039: val_loss did not improve from 3.12954\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.3768 - on_off_loss: 1.7305 - dyskinesia_loss: 0.8511 - tremor_loss: 0.7952 - val_loss: 3.1368 - val_on_off_loss: 1.5958 - val_dyskinesia_loss: 0.7320 - val_tremor_loss: 0.8090\n",
      "Epoch 40/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3661 - on_off_loss: 1.7280 - dyskinesia_loss: 0.8462 - tremor_loss: 0.7919\n",
      "Epoch 00040: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.3660 - on_off_loss: 1.7277 - dyskinesia_loss: 0.8463 - tremor_loss: 0.7920 - val_loss: 3.1388 - val_on_off_loss: 1.5977 - val_dyskinesia_loss: 0.7294 - val_tremor_loss: 0.8117\n",
      "Epoch 41/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3766 - on_off_loss: 1.7336 - dyskinesia_loss: 0.8458 - tremor_loss: 0.7972\n",
      "Epoch 00041: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3762 - on_off_loss: 1.7337 - dyskinesia_loss: 0.8454 - tremor_loss: 0.7971 - val_loss: 3.1371 - val_on_off_loss: 1.5942 - val_dyskinesia_loss: 0.7317 - val_tremor_loss: 0.8112\n",
      "Epoch 42/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3727 - on_off_loss: 1.7288 - dyskinesia_loss: 0.8505 - tremor_loss: 0.7935\n",
      "Epoch 00042: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3728 - on_off_loss: 1.7284 - dyskinesia_loss: 0.8506 - tremor_loss: 0.7938 - val_loss: 3.1309 - val_on_off_loss: 1.5917 - val_dyskinesia_loss: 0.7299 - val_tremor_loss: 0.8093\n",
      "Epoch 43/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3649 - on_off_loss: 1.7301 - dyskinesia_loss: 0.8422 - tremor_loss: 0.7926\n",
      "Epoch 00043: val_loss did not improve from 3.12954\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 3.3649 - on_off_loss: 1.7298 - dyskinesia_loss: 0.8424 - tremor_loss: 0.7927 - val_loss: 3.1445 - val_on_off_loss: 1.6007 - val_dyskinesia_loss: 0.7311 - val_tremor_loss: 0.8127\n",
      "Epoch 44/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3674 - on_off_loss: 1.7258 - dyskinesia_loss: 0.8483 - tremor_loss: 0.7933\n",
      "Epoch 00044: val_loss did not improve from 3.12954\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "500/500 [==============================] - 89s 179ms/step - loss: 3.3677 - on_off_loss: 1.7266 - dyskinesia_loss: 0.8478 - tremor_loss: 0.7933 - val_loss: 3.1381 - val_on_off_loss: 1.5951 - val_dyskinesia_loss: 0.7308 - val_tremor_loss: 0.8123\n"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm2.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=5, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(history.history, open(\"history3.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from addict import Dict\n",
    "history = Dict(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efcb00f6d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.loss)\n",
    "plt.plot(history.val_loss)\n",
    "plt.legend([\"Train Loss Total\", \"Valid Loss Total\"])\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.on_off_loss)\n",
    "plt.plot(history.val_on_off_loss)\n",
    "plt.legend([\"Train MSE on off\", \"Valid MSE on off\"])\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.dyskinesia_loss)\n",
    "plt.plot(history.val_dyskinesia_loss)\n",
    "plt.legend([\"Train MSE dys\", \"Valid MSE dys\"])\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.tremor_loss)\n",
    "plt.plot(history.val_tremor_loss)\n",
    "plt.legend([\"Train MSE tremor\", \"Valid MSE tremor\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try increasing complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_test(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))[0]\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0], example[\"measurement_id\"][0], example[\"subjects\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128, map_example=map_example_to_simple_train)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=512, map_example=map_example_to_simple)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=512, map_example=map_example_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 1\n",
    "num_lin_layers = 5\n",
    "dropout = 0.5\n",
    "lin_h=512\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(64, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(64, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(lin_h)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off, x_dyskinesia, x_tremor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1500, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 1500, 3)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1500, 64)     640         gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 1500, 64)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 750, 64)      0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 750, 64)      256         max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 750, 64)      12352       batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 750, 64)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 375, 64)      0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 375, 64)      256         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 375, 64)      12352       batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 375, 64)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 187, 64)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 187, 64)      256         max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 187, 64)      12352       batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 187, 64)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 93, 64)       0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 93, 64)       256         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 93, 64)       12352       batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 93, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 46, 64)       0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 46, 64)       256         max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 46, 64)       33280       batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 46, 64)       0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 46, 64)       256         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_encoder_lstm (Flatten)  (None, 2944)         0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1507840     flatten_encoder_lstm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          262656      batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 512)          262656      batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 512)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512)          0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 512)          2048        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 512)          2048        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          262656      batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 512)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 512)          2048        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 512)          2048        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 512)          2048        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          262656      batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 512)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512)          0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 512)          2048        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 512)          2048        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 512)          2048        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          262656      batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          262656      batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 512)          262656      batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 512)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 512)          0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 512)          2048        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 512)          2048        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 512)          2048        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          262656      batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          262656      batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 512)          262656      batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 512)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 512)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            513         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            513         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            513         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 1)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 1)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 1)            0           dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,564,803\n",
      "Trainable params: 5,548,675\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(lr=0.001), loss=[\"mean_squared_error\", \"mean_squared_error\", \"mean_squared_error\", ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.1625 - on_off_loss: 2.1100 - dyskinesia_loss: 0.9831 - tremor_loss: 1.0694\n",
      "Epoch 00001: val_loss improved from inf to 3.42741, saving model to /n/scratch2/ms994/cnnlstm3.h5\n",
      "500/500 [==============================] - 115s 229ms/step - loss: 4.1622 - on_off_loss: 2.1101 - dyskinesia_loss: 0.9829 - tremor_loss: 1.0692 - val_loss: 3.4274 - val_on_off_loss: 1.7908 - val_dyskinesia_loss: 0.7592 - val_tremor_loss: 0.8774\n",
      "Epoch 2/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.3696 - on_off_loss: 1.7561 - dyskinesia_loss: 0.7790 - tremor_loss: 0.8346\n",
      "Epoch 00002: val_loss improved from 3.42741 to 3.29686, saving model to /n/scratch2/ms994/cnnlstm3.h5\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 3.3700 - on_off_loss: 1.7570 - dyskinesia_loss: 0.7784 - tremor_loss: 0.8347 - val_loss: 3.2969 - val_on_off_loss: 1.6970 - val_dyskinesia_loss: 0.7553 - val_tremor_loss: 0.8446\n",
      "Epoch 3/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.1836 - on_off_loss: 1.6518 - dyskinesia_loss: 0.7287 - tremor_loss: 0.8031\n",
      "Epoch 00003: val_loss improved from 3.29686 to 3.20483, saving model to /n/scratch2/ms994/cnnlstm3.h5\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 3.1831 - on_off_loss: 1.6514 - dyskinesia_loss: 0.7287 - tremor_loss: 0.8030 - val_loss: 3.2048 - val_on_off_loss: 1.6663 - val_dyskinesia_loss: 0.7253 - val_tremor_loss: 0.8132\n",
      "Epoch 4/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 3.0357 - on_off_loss: 1.5741 - dyskinesia_loss: 0.6950 - tremor_loss: 0.7666\n",
      "Epoch 00004: val_loss improved from 3.20483 to 3.15158, saving model to /n/scratch2/ms994/cnnlstm3.h5\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 3.0370 - on_off_loss: 1.5747 - dyskinesia_loss: 0.6953 - tremor_loss: 0.7669 - val_loss: 3.1516 - val_on_off_loss: 1.6510 - val_dyskinesia_loss: 0.7117 - val_tremor_loss: 0.7889\n",
      "Epoch 5/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.8902 - on_off_loss: 1.5034 - dyskinesia_loss: 0.6594 - tremor_loss: 0.7274\n",
      "Epoch 00005: val_loss improved from 3.15158 to 3.11835, saving model to /n/scratch2/ms994/cnnlstm3.h5\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.8907 - on_off_loss: 1.5040 - dyskinesia_loss: 0.6595 - tremor_loss: 0.7272 - val_loss: 3.1184 - val_on_off_loss: 1.6501 - val_dyskinesia_loss: 0.7116 - val_tremor_loss: 0.7566\n",
      "Epoch 6/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.7672 - on_off_loss: 1.4384 - dyskinesia_loss: 0.6373 - tremor_loss: 0.6916\n",
      "Epoch 00006: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 2.7669 - on_off_loss: 1.4384 - dyskinesia_loss: 0.6370 - tremor_loss: 0.6915 - val_loss: 3.1281 - val_on_off_loss: 1.6655 - val_dyskinesia_loss: 0.7059 - val_tremor_loss: 0.7566\n",
      "Epoch 7/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.6413 - on_off_loss: 1.3776 - dyskinesia_loss: 0.6084 - tremor_loss: 0.6553\n",
      "Epoch 00007: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.6423 - on_off_loss: 1.3779 - dyskinesia_loss: 0.6089 - tremor_loss: 0.6555 - val_loss: 3.1945 - val_on_off_loss: 1.7147 - val_dyskinesia_loss: 0.7115 - val_tremor_loss: 0.7684\n",
      "Epoch 8/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.5259 - on_off_loss: 1.3180 - dyskinesia_loss: 0.5840 - tremor_loss: 0.6238\n",
      "Epoch 00008: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 91s 183ms/step - loss: 2.5253 - on_off_loss: 1.3180 - dyskinesia_loss: 0.5838 - tremor_loss: 0.6235 - val_loss: 3.1246 - val_on_off_loss: 1.6424 - val_dyskinesia_loss: 0.6986 - val_tremor_loss: 0.7835\n",
      "Epoch 9/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.4361 - on_off_loss: 1.2719 - dyskinesia_loss: 0.5643 - tremor_loss: 0.6000\n",
      "Epoch 00009: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 2.4360 - on_off_loss: 1.2719 - dyskinesia_loss: 0.5643 - tremor_loss: 0.5998 - val_loss: 3.1552 - val_on_off_loss: 1.7346 - val_dyskinesia_loss: 0.6915 - val_tremor_loss: 0.7291\n",
      "Epoch 10/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.3405 - on_off_loss: 1.2190 - dyskinesia_loss: 0.5437 - tremor_loss: 0.5778\n",
      "Epoch 00010: val_loss did not improve from 3.11835\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0737419506767766e-05.\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.3405 - on_off_loss: 1.2190 - dyskinesia_loss: 0.5437 - tremor_loss: 0.5777 - val_loss: 3.2628 - val_on_off_loss: 1.8177 - val_dyskinesia_loss: 0.7094 - val_tremor_loss: 0.7357\n",
      "Epoch 11/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.2438 - on_off_loss: 1.1640 - dyskinesia_loss: 0.5285 - tremor_loss: 0.5513\n",
      "Epoch 00011: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 2.2437 - on_off_loss: 1.1636 - dyskinesia_loss: 0.5287 - tremor_loss: 0.5514 - val_loss: 3.1720 - val_on_off_loss: 1.7588 - val_dyskinesia_loss: 0.6829 - val_tremor_loss: 0.7302\n",
      "Epoch 12/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.2177 - on_off_loss: 1.1501 - dyskinesia_loss: 0.5217 - tremor_loss: 0.5460\n",
      "Epoch 00012: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 2.2174 - on_off_loss: 1.1497 - dyskinesia_loss: 0.5217 - tremor_loss: 0.5460 - val_loss: 3.1641 - val_on_off_loss: 1.7459 - val_dyskinesia_loss: 0.6864 - val_tremor_loss: 0.7318\n",
      "Epoch 13/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.2145 - on_off_loss: 1.1528 - dyskinesia_loss: 0.5199 - tremor_loss: 0.5418\n",
      "Epoch 00013: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 2.2145 - on_off_loss: 1.1531 - dyskinesia_loss: 0.5199 - tremor_loss: 0.5415 - val_loss: 3.1610 - val_on_off_loss: 1.7511 - val_dyskinesia_loss: 0.6848 - val_tremor_loss: 0.7251\n",
      "Epoch 14/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1938 - on_off_loss: 1.1404 - dyskinesia_loss: 0.5158 - tremor_loss: 0.5376\n",
      "Epoch 00014: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.1941 - on_off_loss: 1.1407 - dyskinesia_loss: 0.5159 - tremor_loss: 0.5376 - val_loss: 3.1720 - val_on_off_loss: 1.7508 - val_dyskinesia_loss: 0.6907 - val_tremor_loss: 0.7305\n",
      "Epoch 15/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1962 - on_off_loss: 1.1405 - dyskinesia_loss: 0.5150 - tremor_loss: 0.5407\n",
      "Epoch 00015: val_loss did not improve from 3.11835\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.5184373246011094e-07.\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.1958 - on_off_loss: 1.1404 - dyskinesia_loss: 0.5148 - tremor_loss: 0.5406 - val_loss: 3.1783 - val_on_off_loss: 1.7575 - val_dyskinesia_loss: 0.6885 - val_tremor_loss: 0.7323\n",
      "Epoch 16/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1888 - on_off_loss: 1.1358 - dyskinesia_loss: 0.5164 - tremor_loss: 0.5366\n",
      "Epoch 00016: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 2.1890 - on_off_loss: 1.1361 - dyskinesia_loss: 0.5163 - tremor_loss: 0.5366 - val_loss: 3.1779 - val_on_off_loss: 1.7579 - val_dyskinesia_loss: 0.6889 - val_tremor_loss: 0.7311\n",
      "Epoch 17/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1885 - on_off_loss: 1.1344 - dyskinesia_loss: 0.5135 - tremor_loss: 0.5407\n",
      "Epoch 00017: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 2.1881 - on_off_loss: 1.1339 - dyskinesia_loss: 0.5134 - tremor_loss: 0.5407 - val_loss: 3.1709 - val_on_off_loss: 1.7545 - val_dyskinesia_loss: 0.6879 - val_tremor_loss: 0.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1863 - on_off_loss: 1.1388 - dyskinesia_loss: 0.5138 - tremor_loss: 0.5336\n",
      "Epoch 00018: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.1871 - on_off_loss: 1.1397 - dyskinesia_loss: 0.5137 - tremor_loss: 0.5337 - val_loss: 3.1744 - val_on_off_loss: 1.7553 - val_dyskinesia_loss: 0.6885 - val_tremor_loss: 0.7306\n",
      "Epoch 19/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1878 - on_off_loss: 1.1377 - dyskinesia_loss: 0.5120 - tremor_loss: 0.5381\n",
      "Epoch 00019: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 2.1874 - on_off_loss: 1.1375 - dyskinesia_loss: 0.5117 - tremor_loss: 0.5382 - val_loss: 3.1738 - val_on_off_loss: 1.7529 - val_dyskinesia_loss: 0.6902 - val_tremor_loss: 0.7307\n",
      "Epoch 20/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1955 - on_off_loss: 1.1381 - dyskinesia_loss: 0.5182 - tremor_loss: 0.5392\n",
      "Epoch 00020: val_loss did not improve from 3.11835\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.1529216692451882e-08.\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 2.1954 - on_off_loss: 1.1378 - dyskinesia_loss: 0.5182 - tremor_loss: 0.5394 - val_loss: 3.1744 - val_on_off_loss: 1.7572 - val_dyskinesia_loss: 0.6867 - val_tremor_loss: 0.7305\n",
      "Epoch 21/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1838 - on_off_loss: 1.1316 - dyskinesia_loss: 0.5152 - tremor_loss: 0.5371\n",
      "Epoch 00021: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 2.1836 - on_off_loss: 1.1314 - dyskinesia_loss: 0.5149 - tremor_loss: 0.5373 - val_loss: 3.1727 - val_on_off_loss: 1.7545 - val_dyskinesia_loss: 0.6894 - val_tremor_loss: 0.7288\n",
      "Epoch 22/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1887 - on_off_loss: 1.1349 - dyskinesia_loss: 0.5148 - tremor_loss: 0.5390\n",
      "Epoch 00022: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 2.1885 - on_off_loss: 1.1348 - dyskinesia_loss: 0.5146 - tremor_loss: 0.5391 - val_loss: 3.1850 - val_on_off_loss: 1.7644 - val_dyskinesia_loss: 0.6899 - val_tremor_loss: 0.7307\n",
      "Epoch 23/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1971 - on_off_loss: 1.1429 - dyskinesia_loss: 0.5150 - tremor_loss: 0.5391\n",
      "Epoch 00023: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 2.1967 - on_off_loss: 1.1422 - dyskinesia_loss: 0.5152 - tremor_loss: 0.5392 - val_loss: 3.1665 - val_on_off_loss: 1.7497 - val_dyskinesia_loss: 0.6873 - val_tremor_loss: 0.7296\n",
      "Epoch 24/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1842 - on_off_loss: 1.1360 - dyskinesia_loss: 0.5133 - tremor_loss: 0.5349\n",
      "Epoch 00024: val_loss did not improve from 3.11835\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 2.1845 - on_off_loss: 1.1361 - dyskinesia_loss: 0.5134 - tremor_loss: 0.5350 - val_loss: 3.1679 - val_on_off_loss: 1.7515 - val_dyskinesia_loss: 0.6881 - val_tremor_loss: 0.7283\n",
      "Epoch 25/200\n",
      "499/500 [============================>.] - ETA: 0s - loss: 2.1927 - on_off_loss: 1.1343 - dyskinesia_loss: 0.5176 - tremor_loss: 0.5408\n",
      "Epoch 00025: val_loss did not improve from 3.11835\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.777893997636284e-10.\n",
      "500/500 [==============================] - 91s 183ms/step - loss: 2.1938 - on_off_loss: 1.1346 - dyskinesia_loss: 0.5180 - tremor_loss: 0.5412 - val_loss: 3.1801 - val_on_off_loss: 1.7577 - val_dyskinesia_loss: 0.6897 - val_tremor_loss: 0.7327\n"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm3.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=5, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20, min_delta=0.0 o1)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda i, lr: lr*0.8)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(history.history, open(\"history4.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from addict import Dict\n",
    "history = Dict(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa794228da0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.loss)\n",
    "plt.plot(history.val_loss)\n",
    "plt.legend([\"Train Loss Total\", \"Valid Loss Total\"])\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.on_off_loss)\n",
    "plt.plot(history.val_on_off_loss)\n",
    "plt.legend([\"Train MSE on off\", \"Valid MSE on off\"])\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.dyskinesia_loss)\n",
    "plt.plot(history.val_dyskinesia_loss)\n",
    "plt.legend([\"Train MSE dys\", \"Valid MSE dys\"])\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.tremor_loss)\n",
    "plt.plot(history.val_tremor_loss)\n",
    "plt.legend([\"Train MSE tremor\", \"Valid MSE tremor\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "scancel 3230706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = test_data.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to capture an EagerTensor without building a function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-4dd3a342d494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_saveables_for_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   1860\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   1861\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m                                output_shapes=output_shapes, name=name)\n\u001b[0m\u001b[1;32m   1863\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    512\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1120\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[0m\u001b[1;32m   1123\u001b[0m                            \"building a function.\")\n\u001b[1;32m   1124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to capture an EagerTensor without building a function."
     ]
    }
   ],
   "source": [
    "y_onoff_all = []\n",
    "y_dys_all = []\n",
    "y_trem_all = []\n",
    "y_meas_all = []\n",
    "y_subject_all = []\n",
    "y_pred_all = []\n",
    "with tf.Session() as sess:\n",
    "    model = tf.keras.models.load_model(\"/n/scratch2/ms994/cnnlstm3.h5\")   \n",
    "    for i in range(200):\n",
    "        print(i)\n",
    "        xy = test_iter.get_next()\n",
    "\n",
    "        x = xy[0]\n",
    "        y = xy[1]\n",
    "        y_pred_all.append(model.predict(x.numpy(), steps=1))\n",
    "        y_onoff_all.append(y[0].eval())\n",
    "        y_dys_all.append(y[1].eval())   \n",
    "        y_trem_all.append(y[2].eval())\n",
    "        y_meas_all.append(y[3].eval())   \n",
    "        y_subject_all.append(y[4].eval())                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4d0e4eaa76a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/ms994/cnnlstm3.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    283\u001b[0m           ]\n\u001b[1;32m    284\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             logging.warning('Error in loading the saved optimizer '\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    137\u001b[0m             'provided weight shape ' + str(w.shape))\n\u001b[1;32m    138\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2858\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"/n/scratch2/ms994/cnnlstm3.h5\")   \n",
    "model.evaluate(test_data, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 102400, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(y_pred_all).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all = np.hstack(y_pred_all).reshape((3,-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([np.hstack(y_onoff_all), y_pred_all[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102400,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(y_onoff_all).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102400,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(y_meas_all).reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([np.hstack(y_onoff_all),np.vstack(y_meas_all).reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.089744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.212361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.194620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.177829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.135029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.164835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.223837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.219820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.138958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.168932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.159350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.116525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.143847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.108974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.125654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.107664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.219130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.118321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.148627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.136280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.197785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1.139752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.076786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.235008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.146252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1.220056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1.139665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.171625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>1.085028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1.169429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1.175365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1.089767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1.134354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1.213439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1.150485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1.143519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1.144597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1.134740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1.184149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1.117257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1.231148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1.172355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1.165584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1.093357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1.219008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1.066806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1.244681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1.176015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1.056782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1.124172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1.060491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1.255125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1.238739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1             \n",
       "11    1.089744\n",
       "21    1.212361\n",
       "26    1.194620\n",
       "28    1.177829\n",
       "36    1.135029\n",
       "42    1.164835\n",
       "43    1.223837\n",
       "46    1.219820\n",
       "59    1.138958\n",
       "63    1.168932\n",
       "78    1.159350\n",
       "85    1.116525\n",
       "92    1.143847\n",
       "135   1.108974\n",
       "137   1.125654\n",
       "150   1.135802\n",
       "155   1.107664\n",
       "158   1.219130\n",
       "166   1.133333\n",
       "184   1.118321\n",
       "188   1.148627\n",
       "209   1.125000\n",
       "213   1.136280\n",
       "244   1.197785\n",
       "249   1.139752\n",
       "253   1.076786\n",
       "255   1.235008\n",
       "256   1.119048\n",
       "257   1.146252\n",
       "261   1.220056\n",
       "...        ...\n",
       "1533  1.139665\n",
       "1545  1.171625\n",
       "1555  1.085028\n",
       "1566  1.169429\n",
       "1575  1.175365\n",
       "1581  1.089767\n",
       "1583  1.134354\n",
       "1584  1.213439\n",
       "1592  1.150485\n",
       "1606  1.143519\n",
       "1617  1.144597\n",
       "1637  1.134740\n",
       "1654  1.184149\n",
       "1666  1.117257\n",
       "1672  1.231148\n",
       "1673  1.172355\n",
       "1713  1.165584\n",
       "1714  1.093357\n",
       "1720  1.055556\n",
       "1755  1.219008\n",
       "1776  1.066806\n",
       "1783  1.063636\n",
       "1784  1.244681\n",
       "1788  1.176015\n",
       "1801  1.095400\n",
       "1816  1.056782\n",
       "1820  1.124172\n",
       "1827  1.060491\n",
       "1836  1.255125\n",
       "1849  1.238739\n",
       "\n",
       "[203 rows x 1 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.groupby(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T\n",
    "data.columns = [\"True\", \"Pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102400, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa69b5f05c0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(x=\"True\", y=\"Pred\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa6c0542e48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame([np.hstack(y_dys_all), y_pred_all[:, 1]])\n",
    "data = data.T\n",
    "data.columns = [\"True\", \"Pred\"]\n",
    "sns.violinplot(x=\"True\", y=\"Pred\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e62b4e898>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame([np.hstack(y_trem_all), y_pred_all[:, 2]])\n",
    "data = data.T\n",
    "data.columns = [\"True\", \"Pred\"]\n",
    "sns.violinplot(x=\"True\", y=\"Pred\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_df = pd.DataFrame([*y_pred_all.T, np.hstack(y_onoff_all), np.hstack(y_dys_all), np.hstack(y_trem_all), np.vstack(y_meas_all).reshape(-1), np.vstack(y_subject_all).reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492519</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.957210</td>\n",
       "      <td>1.000530</td>\n",
       "      <td>1.346092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.743237</td>\n",
       "      <td>1.385094</td>\n",
       "      <td>1.391631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.906145</td>\n",
       "      <td>0.703602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3    4    5       6     7\n",
       "0  0.948795  0.000000  0.492519  3.0  0.0  0.0  1052.0   1.0\n",
       "1  1.957210  1.000530  1.346092  0.0  0.0  0.0   989.0  18.0\n",
       "2  1.743237  1.385094  1.391631  1.0  0.0  0.0   155.0  12.0\n",
       "3  0.192371  0.000000  1.210087  0.0  0.0  1.0   381.0   3.0\n",
       "4  0.868354  0.906145  0.703602  0.0  1.0  0.0   517.0   3.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_df.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_df = y_pred_all_df.T\n",
    "y_pred_all_df.columns = [\"onoff_pred\", \"dysk_pred\", \"trem_pred\", \"onoff_true\", \"dysk_true\", \"trem_true\", \"m_id\", \"s_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onoff_pred</th>\n",
       "      <th>dysk_pred</th>\n",
       "      <th>trem_pred</th>\n",
       "      <th>onoff_true</th>\n",
       "      <th>dysk_true</th>\n",
       "      <th>trem_true</th>\n",
       "      <th>m_id</th>\n",
       "      <th>s_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492519</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.957210</td>\n",
       "      <td>1.000530</td>\n",
       "      <td>1.346092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.743237</td>\n",
       "      <td>1.385094</td>\n",
       "      <td>1.391631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.906145</td>\n",
       "      <td>0.703602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onoff_pred  dysk_pred  trem_pred  onoff_true  dysk_true  trem_true    m_id  \\\n",
       "0    0.948795   0.000000   0.492519         3.0        0.0        0.0  1052.0   \n",
       "1    1.957210   1.000530   1.346092         0.0        0.0        0.0   989.0   \n",
       "2    1.743237   1.385094   1.391631         1.0        0.0        0.0   155.0   \n",
       "3    0.192371   0.000000   1.210087         0.0        0.0        1.0   381.0   \n",
       "4    0.868354   0.906145   0.703602         0.0        1.0        0.0   517.0   \n",
       "\n",
       "   s_id  \n",
       "0   1.0  \n",
       "1  18.0  \n",
       "2  12.0  \n",
       "3   3.0  \n",
       "4   3.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dysk = y_pred_all_df.groupby(\"m_id\")[\"dysk_pred\", \"dysk_true\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onoff_pred</th>\n",
       "      <th>dysk_pred</th>\n",
       "      <th>trem_pred</th>\n",
       "      <th>onoff_true</th>\n",
       "      <th>dysk_true</th>\n",
       "      <th>trem_true</th>\n",
       "      <th>m_id</th>\n",
       "      <th>s_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492519</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.957210</td>\n",
       "      <td>1.000530</td>\n",
       "      <td>1.346092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.743237</td>\n",
       "      <td>1.385094</td>\n",
       "      <td>1.391631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.906145</td>\n",
       "      <td>0.703602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onoff_pred  dysk_pred  trem_pred  onoff_true  dysk_true  trem_true    m_id  \\\n",
       "0    0.948795   0.000000   0.492519         3.0        0.0        0.0  1052.0   \n",
       "1    1.957210   1.000530   1.346092         0.0        0.0        0.0   989.0   \n",
       "2    1.743237   1.385094   1.391631         1.0        0.0        0.0   155.0   \n",
       "3    0.192371   0.000000   1.210087         0.0        0.0        1.0   381.0   \n",
       "4    0.868354   0.906145   0.703602         0.0        1.0        0.0   517.0   \n",
       "\n",
       "   s_id  \n",
       "0   1.0  \n",
       "1  18.0  \n",
       "2  12.0  \n",
       "3   3.0  \n",
       "4   3.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1170 in test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e3c5f7cf8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(x=\"dysk_true\", y=\"dysk_pred\", data=ensemble_dysk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0ce0aac41084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    344\u001b[0m     value = data_structures.sticky_attribute_assignment(\n\u001b[1;32m    345\u001b[0m         checkpointable=self, value=value, name=name)\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;31m# Keep track of metric instance created in subclassed model/layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     if (not getattr(self, '_setattr_tracking', True) or\n\u001b[1;32m   1607\u001b[0m         getattr(self, '_is_graph_network', False)):\n\u001b[0;32m-> 1608\u001b[0;31m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "model.metrics += model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/200 [===========>..................] - ETA: 1:03 - loss: 6.8676 - on_off_loss: 3.3251 - dyskinesia_loss: 1.5043 - tremor_loss: 2.0383"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d0dcf9c76716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1009\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m           steps=steps)\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0;31m# `ins` can be callable in DistributionStrategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate(test_data, steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add subject classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the data read funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels.subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 1/16 #allow deviation from real rotation with pi/16 std\n",
    "def map_example_to_simple_train(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    update_matrix = tfaxangle2mat(tf.constant(0.0), tf.constant(0.0), tf.constant(1.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(0.0), tf.constant(1.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(1.0), tf.constant(0.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    data = data @ update_matrix\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0], tf.one_hot(example[\"subjects\"][0], 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0], tf.one_hot(example[\"subjects\"][0], 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple_test(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0], tf.one_hot(example[\"subjects\"][0], 16), example[\"measurement_id\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128, map_example=map_example_to_simple_train)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=512, map_example=map_example_to_simple_train)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=512, map_example=map_example_to_simple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = test_data.take(1000).make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mid = []\n",
    "all_on_off = []\n",
    "for i in test_iter:\n",
    "    all_mid.append(i[1][4].numpy())\n",
    "    all_on_off.append(i[1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_mid=np.hstack(all_mid)\n",
    "all_on_off=np.hstack(all_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([all_mid, all_on_off])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1\n",
       "0    \n",
       "11  3\n",
       "21  0\n",
       "26  0\n",
       "28  2\n",
       "36  0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.groupby([0]).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 1\n",
    "num_lin_layers = 5\n",
    "dropout = 0.5\n",
    "lin_h=512\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(64, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(64, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(lin_h)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "\n",
    "#subject classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(lin_h)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x_subject = tf.keras.layers.Dense(len(labels.subject_id.unique()), activation=\"softmax\", name=\"subject\")(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLayer, outputs=[x_on_off, x_dyskinesia, x_tremor, x_subject])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1500, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 1500, 3)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1500, 64)     640         gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 1500, 64)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 750, 64)      0           leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 750, 64)      256         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 750, 64)      12352       batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 750, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 375, 64)      0           leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 375, 64)      256         max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 375, 64)      12352       batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 375, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 187, 64)      0           leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 187, 64)      256         max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 187, 64)      12352       batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 187, 64)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 93, 64)       0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 93, 64)       256         max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 93, 64)       12352       batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 93, 64)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 46, 64)       0           leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 46, 64)       256         max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, 46, 64)       33280       batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 46, 64)       0           cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 46, 64)       256         leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_encoder_lstm (Flatten)  (None, 2944)         0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 512)          1507840     flatten_encoder_lstm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 512)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 512)          0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 512)          2048        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 512)          2048        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 512)          2048        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 512)          262656      batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 512)          262656      batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 512)          262656      batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 512)          2048        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 512)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 512)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 512)          0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 512)          262656      batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 512)          0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 512)          0           leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 512)          0           leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 512)          0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 512)          2048        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 512)          2048        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 512)          2048        dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 512)          0           leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 512)          262656      batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 512)          262656      batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 512)          262656      batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 512)          2048        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 512)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 512)          0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 512)          0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 512)          262656      batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 512)          0           leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 512)          0           leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 512)          0           leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 512)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 512)          2048        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 512)          2048        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 512)          2048        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 512)          0           leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          262656      batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 512)          262656      batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 512)          262656      batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 512)          2048        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 512)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 512)          0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 512)          0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 512)          262656      batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 512)          0           leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 512)          0           leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 512)          0           leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 512)          0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 512)          2048        dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 512)          2048        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 512)          2048        dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 512)          0           leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 512)          262656      batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 512)          262656      batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 512)          262656      batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 512)          2048        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 512)          0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 512)          0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 512)          0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 512)          262656      batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 512)          0           leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 512)          0           leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 512)          0           leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 512)          0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 512)          2048        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 512)          2048        dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 512)          2048        dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 512)          0           leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 512)          262656      batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 512)          262656      batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 512)          262656      batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 512)          2048        dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 512)          0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 512)          0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 512)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 512)          262656      batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 512)          0           leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 512)          0           leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 512)          0           leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 512)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            513         dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1)            513         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            513         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 512)          0           leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 1)            0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 1)            0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 1)            0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subject (Dense)                 (None, 16)           8208        dropout_41[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,896,531\n",
      "Trainable params: 6,875,283\n",
      "Non-trainable params: 21,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(lr=0.001), loss=[\"mean_squared_error\", \"mean_squared_error\", \"mean_squared_error\", \"categorical_crossentropy\"], metrics={\"subject\":[\"categorical_accuracy\"]})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and look at history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm3.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=5, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=40, min_delta=0.01)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda i, lr: lr*0.9)\n",
    "\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from addict import Dict\n",
    "history = Dict(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa50c778780>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.loss)\n",
    "plt.plot(history.val_loss)\n",
    "plt.legend([\"Train Loss Total\", \"Valid Loss Total\"])\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.on_off_loss)\n",
    "plt.plot(history.val_on_off_loss)\n",
    "plt.legend([\"Train MSE on off\", \"Valid MSE on off\"])\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.dyskinesia_loss)\n",
    "plt.plot(history.val_dyskinesia_loss)\n",
    "plt.legend([\"Train MSE dys\", \"Valid MSE dys\"])\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.tremor_loss)\n",
    "plt.plot(history.val_tremor_loss)\n",
    "plt.legend([\"Train MSE tremor\", \"Valid MSE tremor\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"/n/scratch2/ms994/cnnlstm3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 88s 442ms/step - loss: 4.1363 - on_off_loss: 1.9665 - dyskinesia_loss: 0.8381 - tremor_loss: 1.0243 - subject_loss: 0.3074 - subject_categorical_accuracy: 0.5365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.1362968444824215, 1.9665179, 0.8380994, 1.0243233, 0.30735633, 0.5364746]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "y_onoff_all = []\n",
    "y_dys_all = []\n",
    "y_trem_all = []\n",
    "y_meas_all = []\n",
    "y_subject_all = []\n",
    "y_pred_all = []\n",
    "# with tf.Session() as sess:\n",
    "#     model = tf.keras.models.load_model(\"/n/scratch2/ms994/cnnlstm3.h5\")\n",
    "test_iter = test_data.take(100).make_one_shot_iterator()\n",
    "xy = test_iter.get_next()\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    x = xy[0]\n",
    "    y = xy[1]\n",
    "#         y_pred_all.append(model.predict(x, steps=1))\n",
    "    y_onoff_all.append(y[0].numpy())\n",
    "    y_dys_all.append(y[1].numpy())   \n",
    "    y_trem_all.append(y[2].numpy())\n",
    "    y_subject_all.append(y[3].numpy())   \n",
    "    y_meas_all.append(y[4].numpy())                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_meas_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_meas_all = np.hstack(y_meas_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onoff_all = np.hstack(y_onoff_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trem_all = np.hstack(y_trem_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dys_all = np.hstack(y_dys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onoff_pred = [y_pred[0] for y_pred in y_pred_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onoff_pred = np.vstack(y_onoff_pred).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dys_pred = np.vstack([y_pred[1] for y_pred in y_pred_all]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trem_pred = np.vstack([y_pred[2] for y_pred in y_pred_all]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([np.hstack(y_meas_all), y_trem_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 865,  369, 1755,  796,  275])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_meas_all[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6026528507409876"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.T[1] - df.T[2])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51200,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trem_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([np.hstack(y_meas_all), y_trem_all.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1\n",
       "0      \n",
       "21    0\n",
       "26    0\n",
       "28    2\n",
       "36    0\n",
       "42    2\n",
       "43    2\n",
       "46    1\n",
       "59    0\n",
       "78    1\n",
       "85    2\n",
       "92    3\n",
       "135   0\n",
       "137   0\n",
       "155   0\n",
       "158   1\n",
       "166   0\n",
       "184   0\n",
       "188   0\n",
       "209   1\n",
       "213   2\n",
       "244   0\n",
       "249   1\n",
       "253   2\n",
       "255   1\n",
       "256   0\n",
       "257   3\n",
       "261   2\n",
       "268   3\n",
       "275   1\n",
       "283   1\n",
       "...  ..\n",
       "1530  3\n",
       "1533  3\n",
       "1545  0\n",
       "1555  1\n",
       "1566  1\n",
       "1575  1\n",
       "1581  2\n",
       "1583  0\n",
       "1584  1\n",
       "1592  1\n",
       "1606  3\n",
       "1617  1\n",
       "1637  1\n",
       "1654  3\n",
       "1666  1\n",
       "1672  1\n",
       "1673  1\n",
       "1713  0\n",
       "1714  0\n",
       "1755  1\n",
       "1776  1\n",
       "1783  1\n",
       "1784  0\n",
       "1788  2\n",
       "1801  0\n",
       "1816  1\n",
       "1820  0\n",
       "1827  3\n",
       "1836  0\n",
       "1849  1\n",
       "\n",
       "[187 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.groupby(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>865.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.830497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.195117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.775283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1         2\n",
       "0   865.0  0.0  2.830497\n",
       "1   369.0  0.0  0.000000\n",
       "2  1755.0  0.0  0.406653\n",
       "3   796.0  0.0  2.195117\n",
       "4   275.0  0.0  1.775283"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.645669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.847015</td>\n",
       "      <td>0.674631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.677128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>1.065134</td>\n",
       "      <td>0.664181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>1.067616</td>\n",
       "      <td>0.640202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>1.073260</td>\n",
       "      <td>0.699124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>0.981949</td>\n",
       "      <td>0.597167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.563388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.0</th>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.665996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>1.055336</td>\n",
       "      <td>0.697189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78.0</th>\n",
       "      <td>1.091633</td>\n",
       "      <td>0.688055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85.0</th>\n",
       "      <td>1.044776</td>\n",
       "      <td>0.651814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92.0</th>\n",
       "      <td>1.003704</td>\n",
       "      <td>0.637263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135.0</th>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.594242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150.0</th>\n",
       "      <td>1.049793</td>\n",
       "      <td>0.664374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155.0</th>\n",
       "      <td>1.108000</td>\n",
       "      <td>0.680261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158.0</th>\n",
       "      <td>1.014493</td>\n",
       "      <td>0.668772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166.0</th>\n",
       "      <td>1.026119</td>\n",
       "      <td>0.689045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184.0</th>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.683172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188.0</th>\n",
       "      <td>1.059055</td>\n",
       "      <td>0.655561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213.0</th>\n",
       "      <td>1.003623</td>\n",
       "      <td>0.650160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244.0</th>\n",
       "      <td>1.049618</td>\n",
       "      <td>0.668281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249.0</th>\n",
       "      <td>0.947566</td>\n",
       "      <td>0.758324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253.0</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.664035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255.0</th>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.637720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256.0</th>\n",
       "      <td>1.060932</td>\n",
       "      <td>0.676604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257.0</th>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.668431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261.0</th>\n",
       "      <td>1.089219</td>\n",
       "      <td>0.674793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533.0</th>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.569566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545.0</th>\n",
       "      <td>1.067416</td>\n",
       "      <td>0.618189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555.0</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.609326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566.0</th>\n",
       "      <td>1.004167</td>\n",
       "      <td>0.703559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575.0</th>\n",
       "      <td>0.934866</td>\n",
       "      <td>0.683176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581.0</th>\n",
       "      <td>1.003953</td>\n",
       "      <td>0.614067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583.0</th>\n",
       "      <td>1.070588</td>\n",
       "      <td>0.627026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584.0</th>\n",
       "      <td>1.045283</td>\n",
       "      <td>0.622012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592.0</th>\n",
       "      <td>1.028112</td>\n",
       "      <td>0.697546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606.0</th>\n",
       "      <td>1.083682</td>\n",
       "      <td>0.635185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617.0</th>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.645368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637.0</th>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.663427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654.0</th>\n",
       "      <td>1.066929</td>\n",
       "      <td>0.600258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666.0</th>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.668531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672.0</th>\n",
       "      <td>1.008197</td>\n",
       "      <td>0.682986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673.0</th>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.573807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713.0</th>\n",
       "      <td>0.936567</td>\n",
       "      <td>0.653722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714.0</th>\n",
       "      <td>1.052174</td>\n",
       "      <td>0.561075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720.0</th>\n",
       "      <td>1.037313</td>\n",
       "      <td>0.639866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755.0</th>\n",
       "      <td>1.068493</td>\n",
       "      <td>0.688449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776.0</th>\n",
       "      <td>0.895307</td>\n",
       "      <td>0.702339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783.0</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.605746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784.0</th>\n",
       "      <td>1.045455</td>\n",
       "      <td>0.687615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788.0</th>\n",
       "      <td>1.023715</td>\n",
       "      <td>0.658297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816.0</th>\n",
       "      <td>1.034014</td>\n",
       "      <td>0.637588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820.0</th>\n",
       "      <td>0.925267</td>\n",
       "      <td>0.673235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827.0</th>\n",
       "      <td>0.954373</td>\n",
       "      <td>0.749822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836.0</th>\n",
       "      <td>1.063197</td>\n",
       "      <td>0.694001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849.0</th>\n",
       "      <td>1.048780</td>\n",
       "      <td>0.621574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1         2\n",
       "0                         \n",
       "11.0    0.983871  0.645669\n",
       "21.0    0.847015  0.674631\n",
       "26.0    0.980392  0.677128\n",
       "28.0    1.065134  0.664181\n",
       "36.0    1.067616  0.640202\n",
       "42.0    1.073260  0.699124\n",
       "43.0    0.981949  0.597167\n",
       "46.0    0.995984  0.563388\n",
       "59.0    0.941818  0.665996\n",
       "63.0    1.055336  0.697189\n",
       "78.0    1.091633  0.688055\n",
       "85.0    1.044776  0.651814\n",
       "92.0    1.003704  0.637263\n",
       "135.0   0.955823  0.594242\n",
       "137.0   1.000000  0.631482\n",
       "150.0   1.049793  0.664374\n",
       "155.0   1.108000  0.680261\n",
       "158.0   1.014493  0.668772\n",
       "166.0   1.026119  0.689045\n",
       "184.0   0.948276  0.683172\n",
       "188.0   1.059055  0.655561\n",
       "209.0   1.000000  0.667269\n",
       "213.0   1.003623  0.650160\n",
       "244.0   1.049618  0.668281\n",
       "249.0   0.947566  0.758324\n",
       "253.0   1.040000  0.664035\n",
       "255.0   0.967273  0.637720\n",
       "256.0   1.060932  0.676604\n",
       "257.0   0.996124  0.668431\n",
       "261.0   1.089219  0.674793\n",
       "...          ...       ...\n",
       "1533.0  0.978723  0.569566\n",
       "1545.0  1.067416  0.618189\n",
       "1555.0  0.968085  0.609326\n",
       "1566.0  1.004167  0.703559\n",
       "1575.0  0.934866  0.683176\n",
       "1581.0  1.003953  0.614067\n",
       "1583.0  1.070588  0.627026\n",
       "1584.0  1.045283  0.622012\n",
       "1592.0  1.028112  0.697546\n",
       "1606.0  1.083682  0.635185\n",
       "1617.0  0.969811  0.645368\n",
       "1637.0  0.977860  0.663427\n",
       "1654.0  1.066929  0.600258\n",
       "1666.0  0.952555  0.668531\n",
       "1672.0  1.008197  0.682986\n",
       "1673.0  0.950617  0.573807\n",
       "1713.0  0.936567  0.653722\n",
       "1714.0  1.052174  0.561075\n",
       "1720.0  1.037313  0.639866\n",
       "1755.0  1.068493  0.688449\n",
       "1776.0  0.895307  0.702339\n",
       "1783.0  0.958333  0.605746\n",
       "1784.0  1.045455  0.687615\n",
       "1788.0  1.023715  0.658297\n",
       "1801.0  1.000000  0.648995\n",
       "1816.0  1.034014  0.637588\n",
       "1820.0  0.925267  0.673235\n",
       "1827.0  0.954373  0.749822\n",
       "1836.0  1.063197  0.694001\n",
       "1849.0  1.048780  0.621574\n",
       "\n",
       "[203 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.groupby(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_subject_all = np.hstack(y_subject_all)\n",
    "y_meas_all = np.vstack(y_meas_all)\n",
    "\n",
    "y_onoff_all = np.hstack(y_onoff_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "onoff_pred_all = [y_pred[0] for y_pred in y_pred_all[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysk_pred_all = [y_pred[1] for y_pred in y_pred_all[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tremor_pred_all = [y_pred[2] for y_pred in y_pred_all[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 800)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_meas_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x7f03c9491510>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([y_meas_all.reshape(-1), y_onoff_all.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409575</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409577</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409578</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409579</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409580</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409582</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409584</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409585</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409586</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409587</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409588</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409589</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409590</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409591</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409593</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409600 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1\n",
       "0       0.0  3.0\n",
       "1       0.0  1.0\n",
       "2       0.0  0.0\n",
       "3       0.0  1.0\n",
       "4       0.0  0.0\n",
       "5       0.0  3.0\n",
       "6       0.0  1.0\n",
       "7       0.0  0.0\n",
       "8       0.0  1.0\n",
       "9       0.0  1.0\n",
       "10      0.0  0.0\n",
       "11      0.0  2.0\n",
       "12      0.0  0.0\n",
       "13      0.0  1.0\n",
       "14      0.0  0.0\n",
       "15      0.0  0.0\n",
       "16      0.0  3.0\n",
       "17      0.0  1.0\n",
       "18      0.0  0.0\n",
       "19      0.0  3.0\n",
       "20      0.0  1.0\n",
       "21      0.0  0.0\n",
       "22      0.0  1.0\n",
       "23      0.0  0.0\n",
       "24      0.0  2.0\n",
       "25      0.0  1.0\n",
       "26      0.0  2.0\n",
       "27      0.0  2.0\n",
       "28      0.0  3.0\n",
       "29      0.0  0.0\n",
       "...     ...  ...\n",
       "409570  0.0  NaN\n",
       "409571  1.0  NaN\n",
       "409572  0.0  NaN\n",
       "409573  0.0  NaN\n",
       "409574  0.0  NaN\n",
       "409575  0.0  NaN\n",
       "409576  0.0  NaN\n",
       "409577  0.0  NaN\n",
       "409578  0.0  NaN\n",
       "409579  0.0  NaN\n",
       "409580  0.0  NaN\n",
       "409581  0.0  NaN\n",
       "409582  0.0  NaN\n",
       "409583  0.0  NaN\n",
       "409584  0.0  NaN\n",
       "409585  0.0  NaN\n",
       "409586  0.0  NaN\n",
       "409587  1.0  NaN\n",
       "409588  0.0  NaN\n",
       "409589  0.0  NaN\n",
       "409590  0.0  NaN\n",
       "409591  0.0  NaN\n",
       "409592  0.0  NaN\n",
       "409593  0.0  NaN\n",
       "409594  0.0  NaN\n",
       "409595  0.0  NaN\n",
       "409596  0.0  NaN\n",
       "409597  0.0  NaN\n",
       "409598  0.0  NaN\n",
       "409599  0.0  NaN\n",
       "\n",
       "[409600 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeoschedastic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_simple(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return (data, example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],), (example['on_off'][0], example['dyskinesia'][0], example['tremor'][0],)\n",
    "\n",
    "def get_batched_dataset(filenames, batch_size, m_ids, max_queue_size=10,  n_process=4, is_train=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=n_process)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda example: tf_is_in_set(example[\"measurement_id\"][0], tf.constant(m_ids, dtype=tf.int64)))\n",
    "    dataset = dataset.map(map_example_to_simple, num_parallel_calls=n_process)\n",
    "#     dataset = dataset.filter(lambda x, y: tf.not_equal(y[0], -1))\n",
    "    dataset = dataset.filter(lambda x, y: tf.math.reduce_std(x[0]) > 0.05)\n",
    "#     dataset = dataset.filter(lambda x, y: tf.not_equal(y[1], -1))\n",
    "#     dataset = dataset.filter(lambda x, y: tf.not_equal(y[2], -1))\n",
    "\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(2056)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if is_train:\n",
    "        dataset = dataset.prefetch(max_queue_size)\n",
    "    else:\n",
    "        dataset = dataset.prefetch(int(max_queue_size/4)) #store a lot less for the other sets to avoid wasting memory\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Custom loss layer\n",
    "class CustomMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, **kwargs):\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        # initialise log_vars\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),\n",
    "                                              initializer=Constant(0.), trainable=True)]\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "\n",
    "    def multi_loss(self, ys_true, ys_pred):\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\n",
    "            precision = K.exp(-log_var[0])\n",
    "            loss += K.sum(tf.boolean_mask(precision * (y_true - y_pred)**2. + log_var[0], tf.equal(y_true, -1)), -1)\n",
    "        return K.mean(loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return K.concatenate(inputs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_layers = 5\n",
    "num_lstm_layers = 1\n",
    "num_lin_layers = 2\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(16, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.CuDNNLSTM(256, return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flatten_encoder_lstm\")(x)\n",
    "x = tf.keras.layers.Dense(200)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x_shared_flattened = x\n",
    "\n",
    "#one_off\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_on_off = tf.keras.layers.ReLU(name=\"on_off\", max_value=4)(x)\n",
    "x_on_off_input = tf.keras.layers.Input((1,))\n",
    "\n",
    "#tremor\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_dyskinesia = tf.keras.layers.ReLU(name=\"dyskinesia\", max_value=4)(x)\n",
    "x_dyskinesia_input = tf.keras.layers.Input((1,))\n",
    "\n",
    "#montage classify\n",
    "x = x_shared_flattened \n",
    "for k in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x_tremor = tf.keras.layers.ReLU(name=\"tremor\", max_value=4)(x)\n",
    "x_tremor_input = tf.keras.layers.Input((1,))\n",
    "\n",
    "x_homeo = CustomMultiLossLayer(nb_outputs=3)([x_on_off, x_dyskinesia, x_tremor, x_on_off_input, x_dyskinesia_input, x_tremor_input])\n",
    "x_homeo_on_off_out = tf.keras.layers.Lambda(lambda x:  x[3])(x_homeo)\n",
    "x_homeo_dys_out = tf.keras.layers.Lambda(lambda x:  x[4])(x_homeo)\n",
    "x_homeo_tremor_out = tf.keras.layers.Lambda(lambda x:  x[5])(x_homeo)\n",
    "\n",
    "model = tf.keras.Model([inputLayer, x_on_off_input, x_dyskinesia_input, x_tremor_input], [x_homeo_on_off_out, x_homeo_dys_out, x_homeo_tremor_out])\n",
    "model.compile(\"adam\", loss=[\"mean_squared_error\", \"mean_squared_error\", \"mean_squared_error\"], loss_weights=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=256)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Iterator' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-0442aa2929ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearlyStopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(output_generator, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;34m'Keras requires a thread-safe generator when '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             '`use_multiprocessing=False, workers > 1`. ')\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    678\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m   \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Iterator' object is not an iterator"
     ]
    }
   ],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/cnnlstm2.h5\", save_best_only=True, verbose=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit_generator(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[modelCheckpoint, reduceLR, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
